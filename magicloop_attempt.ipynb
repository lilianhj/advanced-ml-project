{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing data, preparing batch processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import preprocessing as pre\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.functional as F\n",
    "import torch.optim as optim\n",
    "import torchtext.data as data\n",
    "import copy\n",
    "import all_models as am"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/bf-repo/preprocessing.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  apply(lambda x: x[0: 1000000])\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data, val_data, TEXT, LABEL = pre.get_data('train_small.csv', 'val_small.csv', 'test_small.csv', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT.build_vocab(train_data)\n",
    "LABEL.build_vocab(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_CUDA = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 5\n",
    "\n",
    "device = torch.device('cuda' if USE_CUDA else 'cpu')\n",
    "\n",
    "TEXT.build_vocab(train_data)\n",
    "LABEL.build_vocab(train_data)\n",
    "\n",
    "train_it, test_it, val_it = data.BucketIterator.splits(\n",
    "    (train_data, test_data, val_data), \n",
    "    batch_size = BATCH_SIZE,\n",
    "    sort_key=lambda x: len(x.alj_text),\n",
    "    sort_within_batch=True,\n",
    "    device = device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, rnn_type, input_size, embedding_size, hidden_size, output_size,\n",
    "                 num_layers, dropout, bidirectional, padding_idx):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(input_size, embedding_size, padding_idx=padding_idx)\n",
    "        self.rnn = getattr(nn, rnn_type.upper())(embedding_size, hidden_size, num_layers, dropout=dropout,\n",
    "                                         bidirectional=bidirectional)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        linear_inp = (hidden_size * 2 if bidirectional else hidden_size)\n",
    "        self.linear = nn.Linear(hidden_size, output_size)\n",
    "             \n",
    "    def forward(self, input):\n",
    "        embed = self.embedding(input)\n",
    "        rnn_out, hidden = self.rnn(embed)\n",
    "        rnn_out = rnn_out[-1]\n",
    "        dropped_rnn_out = self.dropout(rnn_out)\n",
    "        linear_out = self.linear(rnn_out)\n",
    "        return linear_out\n",
    "    \n",
    "    def evaluate(self, preds, labels):\n",
    "        return self.loss_fn(pred, label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordEmbAvg(nn.Module):\n",
    "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim, pad_idx, two_layers=True, dropout_p=0.0):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        # Define an embedding layer, a couple of linear layers, and \n",
    "        # the ReLU non-linearity.\n",
    "\n",
    "        ##YOUR CODE HERE##\n",
    "        self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
    "        if two_layers == True:\n",
    "            self.linear1 = nn.Linear(embedding_dim, hidden_dim)\n",
    "            self.linear2 = nn.Linear(hidden_dim, output_dim) \n",
    "        else:\n",
    "            self.linear1 = nn.Linear(embedding_dim, output_dim)\n",
    "            self.linear2 = None\n",
    "        self.relu = nn.ReLU()\n",
    "        self.drop_layer = nn.Dropout(p=dropout_p)\n",
    "\n",
    "        \n",
    "        \n",
    "    def forward(self, text):\n",
    "\n",
    "        ##YOUR CODE HERE##\n",
    "        embedded = self.embedding(text)\n",
    "        embedded = embedded.mean(0)\n",
    "        if not self.linear2:\n",
    "            linear1_output = self.linear1(embedded)\n",
    "            output = self.relu(linear1_output)\n",
    "            output = self.drop_layer(output)\n",
    "            return output\n",
    "        else:\n",
    "            linear1_output = self.linear1(embedded)\n",
    "            linear2_input = self.relu(linear1_output)\n",
    "            output = self.linear2(linear2_input)\n",
    "            output = self.drop_layer(output)\n",
    "            return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Dev Accuracy: 0.800000011920929 Dev Precision: nan Dev Recall: 0.0 Dev Loss:0.9057289958000183\n",
      "Epoch 1: Dev Accuracy: 0.6000000238418579 Dev Precision: 0.0 Dev Recall: 0.0 Dev Loss:0.911056637763977\n",
      "Epoch 2: Dev Accuracy: 0.6000000238418579 Dev Precision: 0.0 Dev Recall: 0.0 Dev Loss:0.9083573222160339\n",
      "Epoch 3: Dev Accuracy: 0.800000011920929 Dev Precision: nan Dev Recall: 0.0 Dev Loss:0.8956953883171082\n",
      "Epoch 4: Dev Accuracy: 0.800000011920929 Dev Precision: nan Dev Recall: 0.0 Dev Loss:0.8916605114936829\n",
      "Epoch 5: Dev Accuracy: 0.6000000238418579 Dev Precision: 0.0 Dev Recall: 0.0 Dev Loss:1.6293823719024658\n",
      "Epoch 6: Dev Accuracy: 0.800000011920929 Dev Precision: nan Dev Recall: 0.0 Dev Loss:0.8864431381225586\n",
      "Epoch 7: Dev Accuracy: 0.800000011920929 Dev Precision: nan Dev Recall: 0.0 Dev Loss:0.8886189460754395\n",
      "Epoch 8: Dev Accuracy: 0.800000011920929 Dev Precision: nan Dev Recall: 0.0 Dev Loss:0.8981332778930664\n",
      "Epoch 9: Dev Accuracy: 0.800000011920929 Dev Precision: nan Dev Recall: 0.0 Dev Loss:0.897979199886322\n",
      "Epoch 10: Dev Accuracy: 0.6000000238418579 Dev Precision: 0.0 Dev Recall: 0.0 Dev Loss:1.1260080337524414\n",
      "Epoch 11: Dev Accuracy: 0.800000011920929 Dev Precision: nan Dev Recall: 0.0 Dev Loss:0.8830670714378357\n",
      "Epoch 12: Dev Accuracy: 0.800000011920929 Dev Precision: nan Dev Recall: 0.0 Dev Loss:0.8773015141487122\n",
      "Epoch 13: Dev Accuracy: 0.800000011920929 Dev Precision: nan Dev Recall: 0.0 Dev Loss:0.8614024519920349\n",
      "Epoch 14: Dev Accuracy: 0.800000011920929 Dev Precision: nan Dev Recall: 0.0 Dev Loss:0.8585597276687622\n",
      "Epoch 15: Dev Accuracy: 0.800000011920929 Dev Precision: nan Dev Recall: 0.0 Dev Loss:0.8479180335998535\n",
      "Epoch 16: Dev Accuracy: 0.800000011920929 Dev Precision: nan Dev Recall: 0.0 Dev Loss:0.8406187295913696\n",
      "Epoch 17: Dev Accuracy: 0.800000011920929 Dev Precision: nan Dev Recall: 0.0 Dev Loss:0.838347852230072\n",
      "Epoch 18: Dev Accuracy: 0.800000011920929 Dev Precision: nan Dev Recall: 0.0 Dev Loss:0.8162755966186523\n",
      "Epoch 19: Dev Accuracy: 0.800000011920929 Dev Precision: nan Dev Recall: 0.0 Dev Loss:0.8559810519218445\n"
     ]
    }
   ],
   "source": [
    "INPUT_DIM = len(TEXT.vocab)\n",
    "EMBEDDING_SIZE = 100\n",
    "HIDDEN_SIZE = 100\n",
    "OUTPUT_SIZE = 1\n",
    "NUM_LAYERS = 2\n",
    "DROPOUT = 0.5\n",
    "BIDIRECTIONAL = False\n",
    "PADDING_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
    "model = RNN('lstm', INPUT_DIM, EMBEDDING_SIZE, HIDDEN_SIZE, OUTPUT_SIZE,\n",
    "         NUM_LAYERS, DROPOUT, BIDIRECTIONAL, PADDING_IDX)\n",
    "\n",
    "LEARNING_RATE = 0.001\n",
    "train_len = 0\n",
    "train_pos = 0\n",
    "for batch in train_it:\n",
    "    train_len += len(batch.decision_binary)\n",
    "    train_pos += batch.decision_binary.sum().item()\n",
    "POS_WEIGHT = torch.tensor([(train_len - train_pos) / train_pos])\n",
    "if USE_CUDA:\n",
    "    POS_WEIGHT = POS_WEIGHT.cuda()\n",
    "EPOCHS = 20\n",
    "tm = am.Training_module(model, LEARNING_RATE, POS_WEIGHT, USE_CUDA, EPOCHS)\n",
    "\n",
    "#Training the model\n",
    "best_model_acc, best_model_prec, best_model_rec = tm.train_model(train_it, val_it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN(\n",
       "  (embedding): Embedding(10510, 100, padding_idx=1)\n",
       "  (rnn): LSTM(100, 100, num_layers=2, dropout=0.5)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (linear): Linear(in_features=100, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN(\n",
       "  (embedding): Embedding(10510, 100, padding_idx=1)\n",
       "  (rnn): LSTM(100, 100, num_layers=2, dropout=0.5)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (linear): Linear(in_features=100, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model_prec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN(\n",
       "  (embedding): Embedding(10510, 100, padding_idx=1)\n",
       "  (rnn): LSTM(100, 100, num_layers=2, dropout=0.5)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (linear): Linear(in_features=100, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model_rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1269: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "/pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1269: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.757 | Test Acc: 68.89% | Test Prec: 0.00% | Test Rec: nan%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1269: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n"
     ]
    }
   ],
   "source": [
    "tm.model = best_model_acc\n",
    "test_loss, test_acc, test_prec, test_rec = tm.evaluate(test_it)\n",
    "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}% | Test Prec: {test_prec*100:.2f}% | Test Rec: {test_rec*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_nn = WordEmbAvg(INPUT_DIM, EMBEDDING_SIZE, HIDDEN_SIZE, OUTPUT_SIZE, PADDING_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_tm = am.Training_module(simple_nn, LEARNING_RATE, POS_WEIGHT, USE_CUDA, EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Dev Accuracy: 0.6000000238418579 Dev Precision: 0.0 Dev Recall: 0.0 Dev Loss:0.9329513907432556\n",
      "Epoch 1: Dev Accuracy: 0.6000000238418579 Dev Precision: 0.0 Dev Recall: 0.0 Dev Loss:0.9552356600761414\n",
      "Epoch 2: Dev Accuracy: 0.6000000238418579 Dev Precision: 0.0 Dev Recall: 0.0 Dev Loss:1.0157915353775024\n",
      "Epoch 3: Dev Accuracy: 0.6000000238418579 Dev Precision: 0.0 Dev Recall: 0.0 Dev Loss:1.0917619466781616\n",
      "Epoch 4: Dev Accuracy: 0.6000000238418579 Dev Precision: 0.0 Dev Recall: 0.0 Dev Loss:1.0736163854599\n",
      "Epoch 5: Dev Accuracy: 0.6000000238418579 Dev Precision: 0.0 Dev Recall: 0.0 Dev Loss:1.0844529867172241\n",
      "Epoch 6: Dev Accuracy: 0.6000000238418579 Dev Precision: 0.0 Dev Recall: 0.0 Dev Loss:1.2133562564849854\n",
      "Epoch 7: Dev Accuracy: 0.6000000238418579 Dev Precision: 0.0 Dev Recall: 0.0 Dev Loss:1.2626413106918335\n",
      "Epoch 8: Dev Accuracy: 0.6000000238418579 Dev Precision: 0.0 Dev Recall: 0.0 Dev Loss:1.1554826498031616\n",
      "Epoch 9: Dev Accuracy: 0.6000000238418579 Dev Precision: 0.0 Dev Recall: 0.0 Dev Loss:1.270661473274231\n",
      "Epoch 10: Dev Accuracy: 0.6000000238418579 Dev Precision: 0.0 Dev Recall: 0.0 Dev Loss:1.3522993326187134\n",
      "Epoch 11: Dev Accuracy: 0.6000000238418579 Dev Precision: 0.0 Dev Recall: 0.0 Dev Loss:1.442277431488037\n",
      "Epoch 12: Dev Accuracy: 0.6000000238418579 Dev Precision: 0.0 Dev Recall: 0.0 Dev Loss:1.2497369050979614\n",
      "Epoch 13: Dev Accuracy: 0.6000000238418579 Dev Precision: 0.0 Dev Recall: 0.0 Dev Loss:1.3181406259536743\n",
      "Epoch 14: Dev Accuracy: 0.6000000238418579 Dev Precision: 0.0 Dev Recall: 0.0 Dev Loss:1.4325379133224487\n",
      "Epoch 15: Dev Accuracy: 0.800000011920929 Dev Precision: nan Dev Recall: 0.0 Dev Loss:1.1891216039657593\n",
      "Epoch 16: Dev Accuracy: 0.800000011920929 Dev Precision: nan Dev Recall: 0.0 Dev Loss:1.3035739660263062\n",
      "Epoch 17: Dev Accuracy: 0.800000011920929 Dev Precision: nan Dev Recall: 0.0 Dev Loss:1.4680002927780151\n",
      "Epoch 18: Dev Accuracy: 0.6000000238418579 Dev Precision: 0.0 Dev Recall: 0.0 Dev Loss:1.1489629745483398\n",
      "Epoch 19: Dev Accuracy: 0.800000011920929 Dev Precision: nan Dev Recall: 0.0 Dev Loss:1.410115122795105\n"
     ]
    }
   ],
   "source": [
    "simple_best_model_acc, simple_best_model_prec, simple_best_model_rec = simple_tm.train_model(train_it, val_it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordEmbAvg(\n",
       "  (embedding): Embedding(10510, 100)\n",
       "  (linear1): Linear(in_features=100, out_features=100, bias=True)\n",
       "  (linear2): Linear(in_features=100, out_features=1, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (drop_layer): Dropout(p=0.0, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_best_model_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.694 | Test Acc: 55.56% | Test Prec: 16.67% | Test Rec: nan%\n"
     ]
    }
   ],
   "source": [
    "simple_tm.model = simple_best_model_acc\n",
    "simple_test_loss, simple_test_acc, simple_test_prec, simple_test_rec = simple_tm.evaluate(test_it)\n",
    "print(f'Test Loss: {simple_test_loss:.3f} | Test Acc: {simple_test_acc*100:.2f}% | Test Prec: {simple_test_prec*100:.2f}% | Test Rec: {simple_test_rec*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### magic loop? (for vanilla NN)\n",
    "\n",
    "* epochs\n",
    "* drop-outs\n",
    "* embedding\n",
    "* hidden\n",
    "* learning rate\n",
    "* class weight?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['learning_rate', 'num_epochs', 'drop_outs', 'embedding', 'hidden', 'accuracy', 'precision', 'recall', 'loss', 'model_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Dev Accuracy: 0.20000000298023224 Dev Precision: 0.20000000298023224 Dev Recall: 1.0 Dev Loss:0.977103054523468\n",
      "Epoch 1: Dev Accuracy: 0.20000000298023224 Dev Precision: 0.20000000298023224 Dev Recall: 1.0 Dev Loss:1.7017898559570312\n",
      "Epoch 2: Dev Accuracy: 0.6000000238418579 Dev Precision: 0.0 Dev Recall: 0.0 Dev Loss:1.4439719915390015\n",
      "Epoch 3: Dev Accuracy: 0.800000011920929 Dev Precision: nan Dev Recall: 0.0 Dev Loss:1.6903972625732422\n",
      "Epoch 4: Dev Accuracy: 0.4000000059604645 Dev Precision: 0.0 Dev Recall: 0.0 Dev Loss:1.3456724882125854\n",
      "Epoch 0: Dev Accuracy: 0.20000000298023224 Dev Precision: 0.20000000298023224 Dev Recall: 1.0 Dev Loss:0.9261736869812012\n",
      "Epoch 1: Dev Accuracy: 0.4000000059604645 Dev Precision: 0.0 Dev Recall: 0.0 Dev Loss:0.9230678677558899\n",
      "Epoch 2: Dev Accuracy: 0.6000000238418579 Dev Precision: 0.0 Dev Recall: 0.0 Dev Loss:0.9353299140930176\n",
      "Epoch 3: Dev Accuracy: 0.6000000238418579 Dev Precision: 0.0 Dev Recall: 0.0 Dev Loss:1.0450847148895264\n",
      "Epoch 4: Dev Accuracy: 0.6000000238418579 Dev Precision: 0.0 Dev Recall: 0.0 Dev Loss:1.2514110803604126\n",
      "Epoch 0: Dev Accuracy: 0.6000000238418579 Dev Precision: 0.3333333432674408 Dev Recall: 1.0 Dev Loss:0.906524121761322\n",
      "Epoch 1: Dev Accuracy: 0.6000000238418579 Dev Precision: 0.0 Dev Recall: 0.0 Dev Loss:0.9053184390068054\n",
      "Epoch 2: Dev Accuracy: 0.800000011920929 Dev Precision: nan Dev Recall: 0.0 Dev Loss:0.9054899215698242\n",
      "Epoch 3: Dev Accuracy: 0.800000011920929 Dev Precision: nan Dev Recall: 0.0 Dev Loss:0.9072256088256836\n",
      "Epoch 4: Dev Accuracy: 0.800000011920929 Dev Precision: nan Dev Recall: 0.0 Dev Loss:0.9071739315986633\n",
      "Epoch 0: Dev Accuracy: 0.20000000298023224 Dev Precision: 0.20000000298023224 Dev Recall: 1.0 Dev Loss:1.1852149963378906\n",
      "Epoch 1: Dev Accuracy: 0.800000011920929 Dev Precision: nan Dev Recall: 0.0 Dev Loss:1.110597848892212\n",
      "Epoch 2: Dev Accuracy: 0.800000011920929 Dev Precision: nan Dev Recall: 0.0 Dev Loss:2.0091207027435303\n",
      "Epoch 3: Dev Accuracy: 0.6000000238418579 Dev Precision: 0.0 Dev Recall: 0.0 Dev Loss:1.8292264938354492\n",
      "Epoch 4: Dev Accuracy: 0.800000011920929 Dev Precision: nan Dev Recall: 0.0 Dev Loss:2.7511205673217773\n",
      "Epoch 0: Dev Accuracy: 0.4000000059604645 Dev Precision: 0.0 Dev Recall: 0.0 Dev Loss:0.9415125250816345\n",
      "Epoch 1: Dev Accuracy: 0.6000000238418579 Dev Precision: 0.0 Dev Recall: 0.0 Dev Loss:0.997792661190033\n",
      "Epoch 2: Dev Accuracy: 0.6000000238418579 Dev Precision: 0.0 Dev Recall: 0.0 Dev Loss:1.1690648794174194\n",
      "Epoch 3: Dev Accuracy: 0.6000000238418579 Dev Precision: 0.0 Dev Recall: 0.0 Dev Loss:1.5848525762557983\n",
      "Epoch 4: Dev Accuracy: 0.6000000238418579 Dev Precision: 0.0 Dev Recall: 0.0 Dev Loss:1.5608561038970947\n",
      "Epoch 0: Dev Accuracy: 0.800000011920929 Dev Precision: nan Dev Recall: 0.0 Dev Loss:0.896965503692627\n",
      "Epoch 1: Dev Accuracy: 0.800000011920929 Dev Precision: nan Dev Recall: 0.0 Dev Loss:0.8995067477226257\n",
      "Epoch 2: Dev Accuracy: 0.800000011920929 Dev Precision: nan Dev Recall: 0.0 Dev Loss:0.9014779925346375\n",
      "Epoch 3: Dev Accuracy: 0.800000011920929 Dev Precision: nan Dev Recall: 0.0 Dev Loss:0.9039508700370789\n",
      "Epoch 4: Dev Accuracy: 0.800000011920929 Dev Precision: nan Dev Recall: 0.0 Dev Loss:0.9058477282524109\n",
      "Epoch 0: Dev Accuracy: 0.800000011920929 Dev Precision: nan Dev Recall: 0.0 Dev Loss:1.2468440532684326\n",
      "Epoch 1: Dev Accuracy: 0.800000011920929 Dev Precision: nan Dev Recall: 0.0 Dev Loss:1.1141568422317505\n",
      "Epoch 2: Dev Accuracy: 0.800000011920929 Dev Precision: nan Dev Recall: 0.0 Dev Loss:1.6568787097930908\n",
      "Epoch 3: Dev Accuracy: 0.800000011920929 Dev Precision: nan Dev Recall: 0.0 Dev Loss:1.9299894571304321\n",
      "Epoch 4: Dev Accuracy: 0.6000000238418579 Dev Precision: 0.0 Dev Recall: 0.0 Dev Loss:2.1834638118743896\n",
      "Epoch 0: Dev Accuracy: 0.800000011920929 Dev Precision: nan Dev Recall: 0.0 Dev Loss:0.9451591372489929\n",
      "Epoch 1: Dev Accuracy: 0.6000000238418579 Dev Precision: 0.0 Dev Recall: 0.0 Dev Loss:0.9576088786125183\n",
      "Epoch 2: Dev Accuracy: 0.6000000238418579 Dev Precision: 0.0 Dev Recall: 0.0 Dev Loss:1.0547512769699097\n",
      "Epoch 3: Dev Accuracy: 0.6000000238418579 Dev Precision: 0.0 Dev Recall: 0.0 Dev Loss:1.5357414484024048\n",
      "Epoch 4: Dev Accuracy: 0.6000000238418579 Dev Precision: 0.0 Dev Recall: 0.0 Dev Loss:1.6117950677871704\n",
      "Epoch 0: Dev Accuracy: 0.6000000238418579 Dev Precision: 0.0 Dev Recall: 0.0 Dev Loss:0.902784526348114\n",
      "Epoch 1: Dev Accuracy: 0.800000011920929 Dev Precision: nan Dev Recall: 0.0 Dev Loss:0.9031553268432617\n",
      "Epoch 2: Dev Accuracy: 0.800000011920929 Dev Precision: nan Dev Recall: 0.0 Dev Loss:0.9033071398735046\n",
      "Epoch 3: Dev Accuracy: 0.800000011920929 Dev Precision: nan Dev Recall: 0.0 Dev Loss:0.9055272936820984\n",
      "Epoch 4: Dev Accuracy: 0.800000011920929 Dev Precision: nan Dev Recall: 0.0 Dev Loss:0.9081377983093262\n",
      "Epoch 0: Dev Accuracy: 0.6000000238418579 Dev Precision: 0.0 Dev Recall: 0.0 Dev Loss:0.9442024230957031\n",
      "Epoch 1: Dev Accuracy: 0.6000000238418579 Dev Precision: 0.0 Dev Recall: 0.0 Dev Loss:1.711103081703186\n",
      "Epoch 2: Dev Accuracy: 0.800000011920929 Dev Precision: nan Dev Recall: 0.0 Dev Loss:2.918907642364502\n",
      "Epoch 3: Dev Accuracy: 0.800000011920929 Dev Precision: nan Dev Recall: 0.0 Dev Loss:1.252231240272522\n",
      "Epoch 4: Dev Accuracy: 0.800000011920929 Dev Precision: nan Dev Recall: 0.0 Dev Loss:1.9194592237472534\n",
      "Epoch 0: Dev Accuracy: 0.800000011920929 Dev Precision: nan Dev Recall: 0.0 Dev Loss:0.9279428720474243\n",
      "Epoch 1: Dev Accuracy: 0.4000000059604645 Dev Precision: 0.0 Dev Recall: 0.0 Dev Loss:0.9736728668212891\n",
      "Epoch 2: Dev Accuracy: 0.6000000238418579 Dev Precision: 0.0 Dev Recall: 0.0 Dev Loss:1.1274430751800537\n",
      "Epoch 3: Dev Accuracy: 0.6000000238418579 Dev Precision: 0.0 Dev Recall: 0.0 Dev Loss:1.4246858358383179\n",
      "Epoch 4: Dev Accuracy: 0.6000000238418579 Dev Precision: 0.0 Dev Recall: 0.0 Dev Loss:1.3874330520629883\n",
      "Epoch 0: Dev Accuracy: 0.4000000059604645 Dev Precision: 0.0 Dev Recall: 0.0 Dev Loss:0.9161903262138367\n",
      "Epoch 1: Dev Accuracy: 0.4000000059604645 Dev Precision: 0.0 Dev Recall: 0.0 Dev Loss:0.9127733111381531\n",
      "Epoch 2: Dev Accuracy: 0.6000000238418579 Dev Precision: 0.0 Dev Recall: 0.0 Dev Loss:0.9138565063476562\n",
      "Epoch 3: Dev Accuracy: 0.6000000238418579 Dev Precision: 0.0 Dev Recall: 0.0 Dev Loss:0.9176802039146423\n",
      "Epoch 4: Dev Accuracy: 0.6000000238418579 Dev Precision: 0.0 Dev Recall: 0.0 Dev Loss:0.9229176640510559\n",
      "Epoch 0: Dev Accuracy: 0.20000000298023224 Dev Precision: 0.20000000298023224 Dev Recall: 1.0 Dev Loss:0.9516134262084961\n",
      "Epoch 1: Dev Accuracy: 0.6000000238418579 Dev Precision: 0.0 Dev Recall: 0.0 Dev Loss:2.9758615493774414\n",
      "Epoch 2: Dev Accuracy: 0.6000000238418579 Dev Precision: 0.0 Dev Recall: 0.0 Dev Loss:1.1677155494689941\n",
      "Epoch 3: Dev Accuracy: 0.6000000238418579 Dev Precision: 0.0 Dev Recall: 0.0 Dev Loss:0.8936886191368103\n",
      "Epoch 4: Dev Accuracy: 0.6000000238418579 Dev Precision: 0.0 Dev Recall: 0.0 Dev Loss:1.5185954570770264\n",
      "Epoch 0: Dev Accuracy: 0.6000000238418579 Dev Precision: 0.0 Dev Recall: 0.0 Dev Loss:0.933394730091095\n",
      "Epoch 1: Dev Accuracy: 0.6000000238418579 Dev Precision: 0.0 Dev Recall: 0.0 Dev Loss:1.0220214128494263\n",
      "Epoch 2: Dev Accuracy: 0.6000000238418579 Dev Precision: 0.0 Dev Recall: 0.0 Dev Loss:1.1674355268478394\n",
      "Epoch 3: Dev Accuracy: 0.6000000238418579 Dev Precision: 0.0 Dev Recall: 0.0 Dev Loss:1.4269126653671265\n",
      "Epoch 4: Dev Accuracy: 0.6000000238418579 Dev Precision: 0.0 Dev Recall: 0.0 Dev Loss:1.5982636213302612\n",
      "Epoch 0: Dev Accuracy: 0.800000011920929 Dev Precision: nan Dev Recall: 0.0 Dev Loss:0.8980490565299988\n",
      "Epoch 1: Dev Accuracy: 0.800000011920929 Dev Precision: nan Dev Recall: 0.0 Dev Loss:0.9001954197883606\n",
      "Epoch 2: Dev Accuracy: 0.800000011920929 Dev Precision: nan Dev Recall: 0.0 Dev Loss:0.9031793475151062\n",
      "Epoch 3: Dev Accuracy: 0.800000011920929 Dev Precision: nan Dev Recall: 0.0 Dev Loss:0.9049898386001587\n",
      "Epoch 4: Dev Accuracy: 0.800000011920929 Dev Precision: nan Dev Recall: 0.0 Dev Loss:0.9076178669929504\n",
      "Epoch 0: Dev Accuracy: 0.6000000238418579 Dev Precision: 0.0 Dev Recall: 0.0 Dev Loss:0.9560068249702454\n",
      "Epoch 1: Dev Accuracy: 0.6000000238418579 Dev Precision: 0.0 Dev Recall: 0.0 Dev Loss:1.2581626176834106\n",
      "Epoch 2: Dev Accuracy: 0.6000000238418579 Dev Precision: 0.3333333432674408 Dev Recall: 1.0 Dev Loss:3.970106601715088\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Dev Accuracy: 0.6000000238418579 Dev Precision: 0.0 Dev Recall: 0.0 Dev Loss:5.443199634552002\n",
      "Epoch 4: Dev Accuracy: 0.800000011920929 Dev Precision: nan Dev Recall: 0.0 Dev Loss:4.3792948722839355\n",
      "Epoch 0: Dev Accuracy: 0.6000000238418579 Dev Precision: 0.0 Dev Recall: 0.0 Dev Loss:0.94842928647995\n",
      "Epoch 1: Dev Accuracy: 0.6000000238418579 Dev Precision: 0.0 Dev Recall: 0.0 Dev Loss:1.035082221031189\n",
      "Epoch 2: Dev Accuracy: 0.6000000238418579 Dev Precision: 0.0 Dev Recall: 0.0 Dev Loss:1.227357268333435\n",
      "Epoch 3: Dev Accuracy: 0.6000000238418579 Dev Precision: 0.0 Dev Recall: 0.0 Dev Loss:1.585278868675232\n",
      "Epoch 4: Dev Accuracy: 0.6000000238418579 Dev Precision: 0.0 Dev Recall: 0.0 Dev Loss:1.6452722549438477\n",
      "Epoch 0: Dev Accuracy: 0.800000011920929 Dev Precision: nan Dev Recall: 0.0 Dev Loss:0.8996760249137878\n",
      "Epoch 1: Dev Accuracy: 0.800000011920929 Dev Precision: nan Dev Recall: 0.0 Dev Loss:0.9063175320625305\n",
      "Epoch 2: Dev Accuracy: 0.800000011920929 Dev Precision: nan Dev Recall: 0.0 Dev Loss:0.9102433323860168\n",
      "Epoch 3: Dev Accuracy: 0.800000011920929 Dev Precision: nan Dev Recall: 0.0 Dev Loss:0.9163263440132141\n",
      "Epoch 4: Dev Accuracy: 0.800000011920929 Dev Precision: nan Dev Recall: 0.0 Dev Loss:0.9249624609947205\n",
      "Epoch 0: Dev Accuracy: 0.20000000298023224 Dev Precision: 0.20000000298023224 Dev Recall: 1.0 Dev Loss:1.2605326175689697\n",
      "Epoch 1: Dev Accuracy: 0.800000011920929 Dev Precision: nan Dev Recall: 0.0 Dev Loss:0.9843284487724304\n",
      "Epoch 2: Dev Accuracy: 0.6000000238418579 Dev Precision: 0.0 Dev Recall: 0.0 Dev Loss:2.3803398609161377\n",
      "Epoch 3: Dev Accuracy: 0.800000011920929 Dev Precision: nan Dev Recall: 0.0 Dev Loss:1.0815807580947876\n",
      "Epoch 4: Dev Accuracy: 0.6000000238418579 Dev Precision: 0.0 Dev Recall: 0.0 Dev Loss:1.793573260307312\n",
      "Epoch 0: Dev Accuracy: 0.6000000238418579 Dev Precision: 0.0 Dev Recall: 0.0 Dev Loss:0.9174769520759583\n",
      "Epoch 1: Dev Accuracy: 0.6000000238418579 Dev Precision: 0.0 Dev Recall: 0.0 Dev Loss:0.9755253195762634\n",
      "Epoch 2: Dev Accuracy: 0.6000000238418579 Dev Precision: 0.0 Dev Recall: 0.0 Dev Loss:1.2829625606536865\n",
      "Epoch 3: Dev Accuracy: 0.6000000238418579 Dev Precision: 0.0 Dev Recall: 0.0 Dev Loss:1.3639925718307495\n",
      "Epoch 4: Dev Accuracy: 0.6000000238418579 Dev Precision: 0.0 Dev Recall: 0.0 Dev Loss:1.7334480285644531\n",
      "Epoch 0: Dev Accuracy: 0.20000000298023224 Dev Precision: 0.20000000298023224 Dev Recall: 1.0 Dev Loss:0.9270992279052734\n",
      "Epoch 1: Dev Accuracy: 0.4000000059604645 Dev Precision: 0.0 Dev Recall: 0.0 Dev Loss:0.9225553870201111\n",
      "Epoch 2: Dev Accuracy: 0.4000000059604645 Dev Precision: 0.0 Dev Recall: 0.0 Dev Loss:0.9265618324279785\n",
      "Epoch 3: Dev Accuracy: 0.4000000059604645 Dev Precision: 0.0 Dev Recall: 0.0 Dev Loss:0.9289737939834595\n",
      "Epoch 4: Dev Accuracy: 0.4000000059604645 Dev Precision: 0.0 Dev Recall: 0.0 Dev Loss:0.9344139099121094\n",
      "Epoch 0: Dev Accuracy: 0.6000000238418579 Dev Precision: 0.3333333432674408 Dev Recall: 1.0 Dev Loss:1.078481912612915\n",
      "Epoch 1: Dev Accuracy: 0.800000011920929 Dev Precision: nan Dev Recall: 0.0 Dev Loss:1.0593007802963257\n",
      "Epoch 2: Dev Accuracy: 0.800000011920929 Dev Precision: nan Dev Recall: 0.0 Dev Loss:2.5904476642608643\n",
      "Epoch 3: Dev Accuracy: 0.800000011920929 Dev Precision: nan Dev Recall: 0.0 Dev Loss:4.5110602378845215\n",
      "Epoch 4: Dev Accuracy: 0.4000000059604645 Dev Precision: 0.25 Dev Recall: 1.0 Dev Loss:9.23279094696045\n",
      "Epoch 0: Dev Accuracy: 0.6000000238418579 Dev Precision: 0.0 Dev Recall: 0.0 Dev Loss:1.0195177793502808\n",
      "Epoch 1: Dev Accuracy: 0.6000000238418579 Dev Precision: 0.0 Dev Recall: 0.0 Dev Loss:1.0615005493164062\n",
      "Epoch 2: Dev Accuracy: 0.6000000238418579 Dev Precision: 0.0 Dev Recall: 0.0 Dev Loss:1.429547905921936\n",
      "Epoch 3: Dev Accuracy: 0.6000000238418579 Dev Precision: 0.0 Dev Recall: 0.0 Dev Loss:1.160158395767212\n",
      "Epoch 4: Dev Accuracy: 0.800000011920929 Dev Precision: nan Dev Recall: 0.0 Dev Loss:1.7647920846939087\n",
      "Epoch 0: Dev Accuracy: 0.800000011920929 Dev Precision: nan Dev Recall: 0.0 Dev Loss:0.906339168548584\n",
      "Epoch 1: Dev Accuracy: 0.800000011920929 Dev Precision: nan Dev Recall: 0.0 Dev Loss:0.9048023223876953\n",
      "Epoch 2: Dev Accuracy: 0.6000000238418579 Dev Precision: 0.0 Dev Recall: 0.0 Dev Loss:0.9071068167686462\n",
      "Epoch 3: Dev Accuracy: 0.6000000238418579 Dev Precision: 0.0 Dev Recall: 0.0 Dev Loss:0.9077140688896179\n",
      "Epoch 4: Dev Accuracy: 0.6000000238418579 Dev Precision: 0.0 Dev Recall: 0.0 Dev Loss:0.9128284454345703\n",
      "Epoch 0: Dev Accuracy: 0.20000000298023224 Dev Precision: 0.20000000298023224 Dev Recall: 1.0 Dev Loss:0.926578164100647\n",
      "Epoch 1: Dev Accuracy: 0.20000000298023224 Dev Precision: 0.20000000298023224 Dev Recall: 1.0 Dev Loss:0.9361808896064758\n",
      "Epoch 2: Dev Accuracy: 0.800000011920929 Dev Precision: nan Dev Recall: 0.0 Dev Loss:0.8977438807487488\n",
      "Epoch 3: Dev Accuracy: 0.800000011920929 Dev Precision: nan Dev Recall: 0.0 Dev Loss:0.9017757773399353\n",
      "Epoch 4: Dev Accuracy: 0.800000011920929 Dev Precision: nan Dev Recall: 0.0 Dev Loss:0.8864846229553223\n",
      "Epoch 0: Dev Accuracy: 0.800000011920929 Dev Precision: nan Dev Recall: 0.0 Dev Loss:0.9146434664726257\n",
      "Epoch 1: Dev Accuracy: 0.6000000238418579 Dev Precision: 0.0 Dev Recall: 0.0 Dev Loss:0.9439548850059509\n",
      "Epoch 2: Dev Accuracy: 0.4000000059604645 Dev Precision: 0.0 Dev Recall: 0.0 Dev Loss:1.0098199844360352\n",
      "Epoch 3: Dev Accuracy: 0.6000000238418579 Dev Precision: 0.0 Dev Recall: 0.0 Dev Loss:1.0410751104354858\n",
      "Epoch 4: Dev Accuracy: 0.6000000238418579 Dev Precision: 0.0 Dev Recall: 0.0 Dev Loss:1.0611402988433838\n",
      "Epoch 0: Dev Accuracy: 0.20000000298023224 Dev Precision: 0.20000000298023224 Dev Recall: 1.0 Dev Loss:0.9436662793159485\n",
      "Epoch 1: Dev Accuracy: 0.20000000298023224 Dev Precision: 0.20000000298023224 Dev Recall: 1.0 Dev Loss:0.941937267780304\n",
      "Epoch 2: Dev Accuracy: 0.20000000298023224 Dev Precision: 0.20000000298023224 Dev Recall: 1.0 Dev Loss:0.9390100836753845\n",
      "Epoch 3: Dev Accuracy: 0.4000000059604645 Dev Precision: 0.25 Dev Recall: 1.0 Dev Loss:0.9363670349121094\n",
      "Epoch 4: Dev Accuracy: 0.4000000059604645 Dev Precision: 0.0 Dev Recall: 0.0 Dev Loss:0.9347948431968689\n",
      "Epoch 0: Dev Accuracy: 0.4000000059604645 Dev Precision: 0.0 Dev Recall: 0.0 Dev Loss:1.4682682752609253\n",
      "Epoch 1: Dev Accuracy: 0.800000011920929 Dev Precision: nan Dev Recall: 0.0 Dev Loss:1.594604730606079\n",
      "Epoch 2: Dev Accuracy: 0.800000011920929 Dev Precision: nan Dev Recall: 0.0 Dev Loss:0.7948336005210876\n",
      "Epoch 3: Dev Accuracy: 0.4000000059604645 Dev Precision: 0.25 Dev Recall: 1.0 Dev Loss:0.9322476387023926\n",
      "Epoch 4: Dev Accuracy: 0.6000000238418579 Dev Precision: 0.0 Dev Recall: 0.0 Dev Loss:1.5448286533355713\n",
      "Epoch 0: Dev Accuracy: 0.6000000238418579 Dev Precision: 0.0 Dev Recall: 0.0 Dev Loss:0.9168850779533386\n",
      "Epoch 1: Dev Accuracy: 0.6000000238418579 Dev Precision: 0.0 Dev Recall: 0.0 Dev Loss:0.9448884129524231\n",
      "Epoch 2: Dev Accuracy: 0.6000000238418579 Dev Precision: 0.0 Dev Recall: 0.0 Dev Loss:1.076546549797058\n",
      "Epoch 3: Dev Accuracy: 0.6000000238418579 Dev Precision: 0.0 Dev Recall: 0.0 Dev Loss:1.7578266859054565\n",
      "Epoch 4: Dev Accuracy: 0.6000000238418579 Dev Precision: 0.0 Dev Recall: 0.0 Dev Loss:1.7521969079971313\n",
      "Epoch 0: Dev Accuracy: 0.4000000059604645 Dev Precision: 0.0 Dev Recall: 0.0 Dev Loss:0.9211257100105286\n",
      "Epoch 1: Dev Accuracy: 0.4000000059604645 Dev Precision: 0.0 Dev Recall: 0.0 Dev Loss:0.922888457775116\n",
      "Epoch 2: Dev Accuracy: 0.6000000238418579 Dev Precision: 0.0 Dev Recall: 0.0 Dev Loss:0.9321600198745728\n",
      "Epoch 3: Dev Accuracy: 0.6000000238418579 Dev Precision: 0.0 Dev Recall: 0.0 Dev Loss:0.9446555972099304\n",
      "Epoch 4: Dev Accuracy: 0.6000000238418579 Dev Precision: 0.0 Dev Recall: 0.0 Dev Loss:0.9591652154922485\n",
      "Epoch 0: Dev Accuracy: 0.4000000059604645 Dev Precision: 0.0 Dev Recall: 0.0 Dev Loss:1.9736378192901611\n",
      "Epoch 1: Dev Accuracy: 0.4000000059604645 Dev Precision: 0.25 Dev Recall: 1.0 Dev Loss:2.099961042404175\n",
      "Epoch 2: Dev Accuracy: 0.800000011920929 Dev Precision: nan Dev Recall: 0.0 Dev Loss:3.452679395675659\n",
      "Epoch 3: Dev Accuracy: 0.6000000238418579 Dev Precision: 0.3333333432674408 Dev Recall: 1.0 Dev Loss:5.8651347160339355\n",
      "Epoch 4: Dev Accuracy: 0.20000000298023224 Dev Precision: 0.20000000298023224 Dev Recall: 1.0 Dev Loss:4.943170070648193\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Dev Accuracy: 0.6000000238418579 Dev Precision: 0.0 Dev Recall: 0.0 Dev Loss:0.9795486330986023\n",
      "Epoch 1: Dev Accuracy: 0.6000000238418579 Dev Precision: 0.0 Dev Recall: 0.0 Dev Loss:1.0758745670318604\n",
      "Epoch 2: Dev Accuracy: 0.6000000238418579 Dev Precision: 0.0 Dev Recall: 0.0 Dev Loss:1.3479381799697876\n",
      "Epoch 3: Dev Accuracy: 0.6000000238418579 Dev Precision: 0.0 Dev Recall: 0.0 Dev Loss:1.4379669427871704\n",
      "Epoch 4: Dev Accuracy: 0.800000011920929 Dev Precision: nan Dev Recall: 0.0 Dev Loss:1.795578956604004\n",
      "Epoch 0: Dev Accuracy: 0.4000000059604645 Dev Precision: 0.0 Dev Recall: 0.0 Dev Loss:0.920012891292572\n",
      "Epoch 1: Dev Accuracy: 0.6000000238418579 Dev Precision: 0.0 Dev Recall: 0.0 Dev Loss:0.9335242509841919\n",
      "Epoch 2: Dev Accuracy: 0.6000000238418579 Dev Precision: 0.0 Dev Recall: 0.0 Dev Loss:0.9540209174156189\n",
      "Epoch 3: Dev Accuracy: 0.6000000238418579 Dev Precision: 0.0 Dev Recall: 0.0 Dev Loss:0.9683127403259277\n",
      "Epoch 4: Dev Accuracy: 0.6000000238418579 Dev Precision: 0.0 Dev Recall: 0.0 Dev Loss:1.0173323154449463\n",
      "Epoch 0: Dev Accuracy: 0.4000000059604645 Dev Precision: 0.25 Dev Recall: 1.0 Dev Loss:1.2393715381622314\n",
      "Epoch 1: Dev Accuracy: 0.20000000298023224 Dev Precision: 0.20000000298023224 Dev Recall: 1.0 Dev Loss:1.4536163806915283\n",
      "Epoch 2: Dev Accuracy: 0.800000011920929 Dev Precision: nan Dev Recall: 0.0 Dev Loss:4.791358470916748\n",
      "Epoch 3: Dev Accuracy: 0.800000011920929 Dev Precision: nan Dev Recall: 0.0 Dev Loss:9.83173656463623\n",
      "Epoch 4: Dev Accuracy: 0.800000011920929 Dev Precision: nan Dev Recall: 0.0 Dev Loss:10.637056350708008\n",
      "Epoch 0: Dev Accuracy: 0.800000011920929 Dev Precision: nan Dev Recall: 0.0 Dev Loss:0.9226442575454712\n",
      "Epoch 1: Dev Accuracy: 0.6000000238418579 Dev Precision: 0.0 Dev Recall: 0.0 Dev Loss:1.0662931203842163\n",
      "Epoch 2: Dev Accuracy: 0.6000000238418579 Dev Precision: 0.0 Dev Recall: 0.0 Dev Loss:2.0745275020599365\n",
      "Epoch 3: Dev Accuracy: 0.6000000238418579 Dev Precision: 0.0 Dev Recall: 0.0 Dev Loss:1.0917491912841797\n",
      "Epoch 4: Dev Accuracy: 0.800000011920929 Dev Precision: nan Dev Recall: 0.0 Dev Loss:2.1926372051239014\n",
      "Epoch 0: Dev Accuracy: 0.800000011920929 Dev Precision: nan Dev Recall: 0.0 Dev Loss:0.915217399597168\n",
      "Epoch 1: Dev Accuracy: 0.6000000238418579 Dev Precision: 0.0 Dev Recall: 0.0 Dev Loss:0.9182304739952087\n",
      "Epoch 2: Dev Accuracy: 0.6000000238418579 Dev Precision: 0.0 Dev Recall: 0.0 Dev Loss:0.9235612750053406\n",
      "Epoch 3: Dev Accuracy: 0.6000000238418579 Dev Precision: 0.0 Dev Recall: 0.0 Dev Loss:0.9366998672485352\n",
      "Epoch 4: Dev Accuracy: 0.6000000238418579 Dev Precision: 0.0 Dev Recall: 0.0 Dev Loss:0.9493093490600586\n",
      "Epoch 0: Dev Accuracy: 0.6000000238418579 Dev Precision: 0.0 Dev Recall: 0.0 Dev Loss:0.8844577074050903\n",
      "Epoch 1: Dev Accuracy: 0.800000011920929 Dev Precision: nan Dev Recall: 0.0 Dev Loss:0.8789469003677368\n",
      "Epoch 2: Dev Accuracy: 0.800000011920929 Dev Precision: 0.5 Dev Recall: 1.0 Dev Loss:0.8766641020774841\n",
      "Epoch 3: Dev Accuracy: 0.800000011920929 Dev Precision: nan Dev Recall: 0.0 Dev Loss:1.0414961576461792\n",
      "Epoch 4: Dev Accuracy: 0.800000011920929 Dev Precision: nan Dev Recall: 0.0 Dev Loss:1.2278670072555542\n",
      "Epoch 0: Dev Accuracy: 0.6000000238418579 Dev Precision: 0.0 Dev Recall: 0.0 Dev Loss:1.3477015495300293\n",
      "Epoch 1: Dev Accuracy: 0.6000000238418579 Dev Precision: 0.0 Dev Recall: 0.0 Dev Loss:1.0438820123672485\n",
      "Epoch 2: Dev Accuracy: 0.6000000238418579 Dev Precision: 0.0 Dev Recall: 0.0 Dev Loss:1.2919671535491943\n",
      "Epoch 3: Dev Accuracy: 0.6000000238418579 Dev Precision: 0.0 Dev Recall: 0.0 Dev Loss:1.8108352422714233\n",
      "Epoch 4: Dev Accuracy: 0.800000011920929 Dev Precision: nan Dev Recall: 0.0 Dev Loss:1.0396976470947266\n",
      "Epoch 0: Dev Accuracy: 0.800000011920929 Dev Precision: nan Dev Recall: 0.0 Dev Loss:0.8955391049385071\n",
      "Epoch 1: Dev Accuracy: 0.800000011920929 Dev Precision: nan Dev Recall: 0.0 Dev Loss:0.8996369242668152\n",
      "Epoch 2: Dev Accuracy: 0.800000011920929 Dev Precision: nan Dev Recall: 0.0 Dev Loss:0.9016544222831726\n",
      "Epoch 3: Dev Accuracy: 0.800000011920929 Dev Precision: nan Dev Recall: 0.0 Dev Loss:0.9019500613212585\n",
      "Epoch 4: Dev Accuracy: 0.800000011920929 Dev Precision: nan Dev Recall: 0.0 Dev Loss:0.9065483212471008\n",
      "Epoch 0: Dev Accuracy: 0.20000000298023224 Dev Precision: 0.20000000298023224 Dev Recall: 1.0 Dev Loss:1.7348644733428955\n",
      "Epoch 1: Dev Accuracy: 0.20000000298023224 Dev Precision: 0.20000000298023224 Dev Recall: 1.0 Dev Loss:0.9182328581809998\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-d53eb9c84654>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m                     \u001b[0mmod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWordEmbAvg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mINPUT_DIM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membed_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOUTPUT_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPADDING_IDX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout_p\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdropout_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                     \u001b[0mtrm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTraining_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearn_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPOS_WEIGHT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUSE_CUDA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m                     \u001b[0mbest_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_prec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_rec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_it\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_it\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m                     \u001b[0mtrm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbest_acc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m                     \u001b[0mtest_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_prec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_rec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_it\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/bf-repo/all_models.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(self, train_iterator, dev_iterator)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0mbest_model_rec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_iterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m             \u001b[0mdev_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_prec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_rec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdev_iterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch {epoch}: Dev Accuracy: {dev_acc} Dev Precision: {dev_prec} Dev Recall: {dev_rec} Dev Loss:{dev_loss}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/bf-repo/all_models.py\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m           \u001b[0;31m# batch.text has the texts and batch.label has the labels.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchtext/data/iterator.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    154\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m                         \u001b[0mminibatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0mBatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mminibatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchtext/data/batch.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, dataset, device)\u001b[0m\n\u001b[1;32m     32\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mfield\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m                     \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m                     \u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfield\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchtext/data/field.py\u001b[0m in \u001b[0;36mprocess\u001b[0;34m(self, batch, device)\u001b[0m\n\u001b[1;32m    235\u001b[0m         \"\"\"\n\u001b[1;32m    236\u001b[0m         \u001b[0mpadded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m         \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumericalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchtext/data/field.py\u001b[0m in \u001b[0;36mnumericalize\u001b[0;34m(self, arr, device)\u001b[0m\n\u001b[1;32m    334\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_vocab\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequential\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 336\u001b[0;31m                 \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstoi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    337\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m                 \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstoi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchtext/data/field.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    334\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_vocab\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequential\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 336\u001b[0;31m                 \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstoi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    337\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m                 \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstoi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchtext/data/field.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    334\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_vocab\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequential\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 336\u001b[0;31m                 \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstoi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    337\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m                 \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstoi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "INPUT_DIM = len(TEXT.vocab)\n",
    "OUTPUT_SIZE = 1\n",
    "PADDING_IDX = 0\n",
    "train_len = 0\n",
    "train_pos = 0\n",
    "for batch in train_it:\n",
    "    train_len += len(batch.decision_binary)\n",
    "    train_pos += batch.decision_binary.sum().item()\n",
    "POS_WEIGHT = torch.tensor([(train_len - train_pos) / train_pos])\n",
    "if USE_CUDA:\n",
    "    POS_WEIGHT = POS_WEIGHT.cuda()\n",
    "\n",
    "for num_epoch in [5, 10, 20, 25]:\n",
    "    for dropout_rate in [0, 0.1, 0.25, 0.5, 0.75]:\n",
    "        for embed_dim in [20, 32, 64, 100]:\n",
    "            for hidden_dim in [10, 25, 40, 50]:\n",
    "                for learn_rate in [0.1, 0.01, 0.001]:\n",
    "                    mod = WordEmbAvg(INPUT_DIM, embed_dim, hidden_dim, OUTPUT_SIZE, PADDING_IDX, dropout_p=dropout_rate)\n",
    "                    trm = am.Training_module(mod, learn_rate, POS_WEIGHT, USE_CUDA, num_epoch)\n",
    "                    best_acc, best_prec, best_rec = trm.train_model(train_it, val_it)\n",
    "                    trm.model = best_acc\n",
    "                    test_loss, test_acc, test_prec, test_rec = trm.evaluate(test_it)\n",
    "                    row = [learn_rate, num_epoch, dropout_rate, embed_dim, hidden_dim, test_acc*100, test_prec*100, test_rec*100, test_loss, \"most_accurate\"]\n",
    "                    df.loc[len(df)] = row\n",
    "                    trm.model = best_prec\n",
    "                    test_loss, test_acc, test_prec, test_rec = trm.evaluate(test_it)\n",
    "                    row = [learn_rate, num_epoch, dropout_rate, embed_dim, hidden_dim, test_acc*100, test_prec*100, test_rec*100, test_loss, \"most_precise\"]\n",
    "                    df.loc[len(df)] = row\n",
    "                    trm.model = best_rec\n",
    "                    test_loss, test_acc, test_prec, test_rec = trm.evaluate(test_it)\n",
    "                    row = [learn_rate, num_epoch, dropout_rate, embed_dim, hidden_dim, test_acc*100, test_prec*100, test_rec*100, test_loss, \"most_recall\"]\n",
    "                    df.loc[len(df)] = row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adv-ml",
   "language": "python",
   "name": "adv-ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
