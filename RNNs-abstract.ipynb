{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing data, preparing batch processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import preprocessing as pre\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.functional as F\n",
    "import torch.optim as optim\n",
    "import torchtext.data as data\n",
    "import copy\n",
    "import all_models as am"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/lh-repo/preprocessing.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  apply(lambda x: x[0: 1000000])\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data, val_data, TEXT, LABEL = pre.get_data('train_small.csv', 'val_small.csv', 'test_small.csv', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT.build_vocab(train_data)\n",
    "LABEL.build_vocab(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_CUDA = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 5\n",
    "\n",
    "device = torch.device('cuda' if USE_CUDA else 'cpu')\n",
    "\n",
    "TEXT.build_vocab(train_data)\n",
    "LABEL.build_vocab(train_data)\n",
    "\n",
    "train_it, test_it, val_it = data.BucketIterator.splits(\n",
    "    (train_data, test_data, val_data), \n",
    "    batch_size = BATCH_SIZE,\n",
    "    sort_key=lambda x: len(x.alj_text),\n",
    "    sort_within_batch=True,\n",
    "    device = device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, rnn_type, input_size, embedding_size, hidden_size, output_size,\n",
    "                 num_layers, dropout, bidirectional, padding_idx):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(input_size, embedding_size, padding_idx=padding_idx)\n",
    "        self.rnn = getattr(nn, rnn_type.upper())(embedding_size, hidden_size, num_layers, dropout=dropout,\n",
    "                                         bidirectional=bidirectional)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        linear_inp = (hidden_size * 2 if bidirectional else hidden_size)\n",
    "        self.linear = nn.Linear(hidden_size, output_size)\n",
    "             \n",
    "    def forward(self, input):\n",
    "        embed = self.embedding(input)\n",
    "        rnn_out, hidden = self.rnn(embed)\n",
    "        rnn_out = rnn_out[-1]\n",
    "        dropped_rnn_out = self.dropout(rnn_out)\n",
    "        linear_out = self.linear(rnn_out)\n",
    "        return linear_out\n",
    "    \n",
    "    def evaluate(self, preds, labels):\n",
    "        return self.loss_fn(pred, label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Dev Accuracy: 0.800000011920929 Dev Precision: nan Dev Recall: 0.0 Dev Loss:0.9057289958000183\n",
      "Epoch 1: Dev Accuracy: 0.6000000238418579 Dev Precision: 0.0 Dev Recall: 0.0 Dev Loss:0.911056637763977\n",
      "Epoch 2: Dev Accuracy: 0.6000000238418579 Dev Precision: 0.0 Dev Recall: 0.0 Dev Loss:0.9083573222160339\n",
      "Epoch 3: Dev Accuracy: 0.800000011920929 Dev Precision: nan Dev Recall: 0.0 Dev Loss:0.8956953883171082\n",
      "Epoch 4: Dev Accuracy: 0.800000011920929 Dev Precision: nan Dev Recall: 0.0 Dev Loss:0.8916605114936829\n",
      "Epoch 5: Dev Accuracy: 0.6000000238418579 Dev Precision: 0.0 Dev Recall: 0.0 Dev Loss:1.6293823719024658\n",
      "Epoch 6: Dev Accuracy: 0.800000011920929 Dev Precision: nan Dev Recall: 0.0 Dev Loss:0.8864431381225586\n",
      "Epoch 7: Dev Accuracy: 0.800000011920929 Dev Precision: nan Dev Recall: 0.0 Dev Loss:0.8886189460754395\n",
      "Epoch 8: Dev Accuracy: 0.800000011920929 Dev Precision: nan Dev Recall: 0.0 Dev Loss:0.8981332778930664\n",
      "Epoch 9: Dev Accuracy: 0.800000011920929 Dev Precision: nan Dev Recall: 0.0 Dev Loss:0.897979199886322\n",
      "Epoch 10: Dev Accuracy: 0.6000000238418579 Dev Precision: 0.0 Dev Recall: 0.0 Dev Loss:1.1260080337524414\n",
      "Epoch 11: Dev Accuracy: 0.800000011920929 Dev Precision: nan Dev Recall: 0.0 Dev Loss:0.8830670714378357\n",
      "Epoch 12: Dev Accuracy: 0.800000011920929 Dev Precision: nan Dev Recall: 0.0 Dev Loss:0.8773015141487122\n",
      "Epoch 13: Dev Accuracy: 0.800000011920929 Dev Precision: nan Dev Recall: 0.0 Dev Loss:0.8614024519920349\n",
      "Epoch 14: Dev Accuracy: 0.800000011920929 Dev Precision: nan Dev Recall: 0.0 Dev Loss:0.8585597276687622\n",
      "Epoch 15: Dev Accuracy: 0.800000011920929 Dev Precision: nan Dev Recall: 0.0 Dev Loss:0.8479180335998535\n",
      "Epoch 16: Dev Accuracy: 0.800000011920929 Dev Precision: nan Dev Recall: 0.0 Dev Loss:0.8406187295913696\n",
      "Epoch 17: Dev Accuracy: 0.800000011920929 Dev Precision: nan Dev Recall: 0.0 Dev Loss:0.838347852230072\n",
      "Epoch 18: Dev Accuracy: 0.800000011920929 Dev Precision: nan Dev Recall: 0.0 Dev Loss:0.8162755966186523\n",
      "Epoch 19: Dev Accuracy: 0.800000011920929 Dev Precision: nan Dev Recall: 0.0 Dev Loss:0.8559810519218445\n"
     ]
    }
   ],
   "source": [
    "INPUT_DIM = len(TEXT.vocab)\n",
    "EMBEDDING_SIZE = 100\n",
    "HIDDEN_SIZE = 100\n",
    "OUTPUT_SIZE = 1\n",
    "NUM_LAYERS = 2\n",
    "DROPOUT = 0.5\n",
    "BIDIRECTIONAL = False\n",
    "PADDING_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
    "model = RNN('lstm', INPUT_DIM, EMBEDDING_SIZE, HIDDEN_SIZE, OUTPUT_SIZE,\n",
    "         NUM_LAYERS, DROPOUT, BIDIRECTIONAL, PADDING_IDX)\n",
    "\n",
    "LEARNING_RATE = 0.001\n",
    "train_len = 0\n",
    "train_pos = 0\n",
    "for batch in train_it:\n",
    "    train_len += len(batch.decision_binary)\n",
    "    train_pos += batch.decision_binary.sum().item()\n",
    "POS_WEIGHT = torch.tensor([(train_len - train_pos) / train_pos])\n",
    "if USE_CUDA:\n",
    "    POS_WEIGHT = POS_WEIGHT.cuda()\n",
    "EPOCHS = 20\n",
    "tm = am.Training_module(model, LEARNING_RATE, POS_WEIGHT, USE_CUDA, EPOCHS)\n",
    "\n",
    "#Training the model\n",
    "best_model_acc, best_model_prec, best_model_rec = tm.train_model(train_it, val_it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN(\n",
       "  (embedding): Embedding(10510, 100, padding_idx=1)\n",
       "  (rnn): LSTM(100, 100, num_layers=2, dropout=0.5)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (linear): Linear(in_features=100, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN(\n",
       "  (embedding): Embedding(10510, 100, padding_idx=1)\n",
       "  (rnn): LSTM(100, 100, num_layers=2, dropout=0.5)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (linear): Linear(in_features=100, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model_prec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN(\n",
       "  (embedding): Embedding(10510, 100, padding_idx=1)\n",
       "  (rnn): LSTM(100, 100, num_layers=2, dropout=0.5)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (linear): Linear(in_features=100, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model_rec"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adv-ml",
   "language": "python",
   "name": "adv-ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
