{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNNs with Law2Vec embeddings\n",
    "\n",
    "## Importing data, pre-trained embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from itertools import product\n",
    "from numpy import isnan\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchtext.data as data\n",
    "import torchtext.vocab as vocab\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "sys.path.append('../data_pipeline/')\n",
    "import preprocessing as pre\n",
    "from training import TrainingModule\n",
    "\n",
    "SEED = 1312\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../data_pipeline/preprocessing.py:68: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sans_nulls_df['alj_text'] = sans_nulls_df['alj_text'].str.slice(0, 1000000)\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data, val_data, TEXT, LABEL = pre.get_data(\n",
    "    'train_small.csv', 'val_small.csv', 'test_small.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_CUDA = torch.cuda.is_available()\n",
    "\n",
    "vectors = vocab.Vectors('../embeds/Law2Vec.100d.txt') # Law2Vec available from https://archive.org/details/Law2Vec\n",
    "\n",
    "TEXT.build_vocab(train_data, vectors=vectors,\n",
    "                 unk_init = torch.Tensor.normal_)\n",
    "LABEL.build_vocab(train_data)\n",
    "\n",
    "BATCH_SIZE = 5\n",
    "\n",
    "train_it, test_it, val_it = data.BucketIterator.splits(\n",
    "    (train_data, test_data, val_data), \n",
    "    batch_size = BATCH_SIZE,\n",
    "    sort_key=lambda x: len(x.alj_text),\n",
    "    sort_within_batch=True,\n",
    "    device = torch.device('cuda' if USE_CUDA else 'cpu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking pretrained vectors have been applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.6415, -0.5367, -0.3537, -0.0634, -0.1798,  0.0626, -0.1836, -0.2705,\n",
       "         0.2504,  0.5061,  0.4746, -0.2351, -0.0465,  0.3184,  0.8974,  0.0470,\n",
       "        -0.2594,  0.3485, -0.3356,  0.1163,  0.2207,  0.2707,  0.4748,  0.1122,\n",
       "        -0.1188, -0.0790,  0.4377, -0.4711,  0.1401, -0.0234, -0.2009, -0.2143,\n",
       "         0.1335, -0.4407,  0.4077, -0.0634,  0.5104,  0.1820, -0.4729, -0.1758,\n",
       "         0.6194,  0.5708, -0.3034, -0.3658,  0.1609,  0.0753, -0.2024, -0.1472,\n",
       "         0.0665,  0.1823,  0.3091, -0.0913,  0.2495,  0.0777, -0.1873, -0.5850,\n",
       "        -0.3243,  0.1540, -0.5094,  0.6227,  0.1163, -0.6202, -0.4416, -0.3509,\n",
       "        -0.5760, -0.4837, -0.6283,  0.0938,  0.3528, -0.0674, -0.7097, -0.2053,\n",
       "        -0.6007, -0.1306,  0.0146, -0.0830,  0.5486, -0.2328, -0.3193,  0.1496,\n",
       "        -0.1635,  0.0755, -0.2594, -0.0317,  0.1249, -0.5599,  0.0722, -0.0369,\n",
       "         0.3139,  0.0102, -0.3353,  0.1142, -0.1163,  0.1505,  0.0952,  0.0206,\n",
       "        -0.0733, -0.4851,  0.4995,  0.0404])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors['medicare']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.6415, -0.5367, -0.3537, -0.0634, -0.1798,  0.0626, -0.1836, -0.2705,\n",
       "         0.2504,  0.5061,  0.4746, -0.2351, -0.0465,  0.3184,  0.8974,  0.0470,\n",
       "        -0.2594,  0.3485, -0.3356,  0.1163,  0.2207,  0.2707,  0.4748,  0.1122,\n",
       "        -0.1188, -0.0790,  0.4377, -0.4711,  0.1401, -0.0234, -0.2009, -0.2143,\n",
       "         0.1335, -0.4407,  0.4077, -0.0634,  0.5104,  0.1820, -0.4729, -0.1758,\n",
       "         0.6194,  0.5708, -0.3034, -0.3658,  0.1609,  0.0753, -0.2024, -0.1472,\n",
       "         0.0665,  0.1823,  0.3091, -0.0913,  0.2495,  0.0777, -0.1873, -0.5850,\n",
       "        -0.3243,  0.1540, -0.5094,  0.6227,  0.1163, -0.6202, -0.4416, -0.3509,\n",
       "        -0.5760, -0.4837, -0.6283,  0.0938,  0.3528, -0.0674, -0.7097, -0.2053,\n",
       "        -0.6007, -0.1306,  0.0146, -0.0830,  0.5486, -0.2328, -0.3193,  0.1496,\n",
       "        -0.1635,  0.0755, -0.2594, -0.0317,  0.1249, -0.5599,  0.0722, -0.0369,\n",
       "         0.3139,  0.0102, -0.3353,  0.1142, -0.1163,  0.1505,  0.0952,  0.0206,\n",
       "        -0.0733, -0.4851,  0.4995,  0.0404])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT.vocab.vectors[TEXT.vocab.stoi['medicare']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNPtEmbeds(nn.Module):\n",
    "    \n",
    "    def __init__(self, rnn_type, input_size, embedding_size,\n",
    "                 hidden_size, output_size, num_layers,\n",
    "                 dropout, bidirectional, padding_idx):\n",
    "    \n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding\\\n",
    "                           .from_pretrained(TEXT.vocab.vectors)\n",
    "\n",
    "        self.rnn = getattr(nn, rnn_type.upper())\\\n",
    "                          (embedding_size, hidden_size, num_layers,\n",
    "                           dropout=(dropout if num_layers > 1 else 0),\n",
    "                           bidirectional=bidirectional)\n",
    "        \n",
    "        self.leakyrelu = nn.LeakyReLU()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        linear_inp = (hidden_size * 2 if bidirectional else hidden_size)\n",
    "        self.linear = nn.Linear(linear_inp, output_size)\n",
    "             \n",
    "    def forward(self, input):\n",
    "        embed = self.embedding(input)\n",
    "        rnn_out, hidden = self.rnn(embed)\n",
    "        rnn_out = rnn_out[-1]\n",
    "        rnn_out = self.leakyrelu(rnn_out)\n",
    "        rnn_out = self.dropout(rnn_out)\n",
    "        linear_out = self.linear(rnn_out)\n",
    "        return linear_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Architecture #0\n",
      "--------------------\n",
      "Epoch 0: Dev Accuracy: 0.7500; Dev Precision: nan; Dev Recall: 0.0000; Dev Loss:0.8154\n",
      "Epoch 1: Dev Accuracy: 0.5000; Dev Precision: 0.0000; Dev Recall: 0.0000; Dev Loss:0.8644\n",
      "Epoch 2: Dev Accuracy: 0.5000; Dev Precision: 0.0000; Dev Recall: 0.0000; Dev Loss:0.9077\n",
      "Epoch 3: Dev Accuracy: 0.5000; Dev Precision: 0.0000; Dev Recall: 0.0000; Dev Loss:0.8931\n",
      "Epoch 4: Dev Accuracy: 0.5000; Dev Precision: 0.0000; Dev Recall: 0.0000; Dev Loss:0.8907\n",
      "Epoch 5: Dev Accuracy: 0.5000; Dev Precision: 0.0000; Dev Recall: 0.0000; Dev Loss:0.8681\n",
      "Epoch 6: Dev Accuracy: 0.5000; Dev Precision: 0.0000; Dev Recall: 0.0000; Dev Loss:0.8629\n",
      "Epoch 7: Dev Accuracy: 0.5000; Dev Precision: 0.0000; Dev Recall: 0.0000; Dev Loss:0.8593\n",
      "Epoch 8: Dev Accuracy: 0.7500; Dev Precision: nan; Dev Recall: 0.0000; Dev Loss:0.8518\n",
      "Epoch 9: Dev Accuracy: 0.7500; Dev Precision: 0.5000; Dev Recall: 1.0000; Dev Loss:0.6813\n",
      "--------------------\n",
      "\n",
      "Architecture #1\n",
      "--------------------\n",
      "Epoch 0: Dev Accuracy: 0.2500; Dev Precision: 0.2500; Dev Recall: 1.0000; Dev Loss:0.8677\n",
      "Epoch 1: Dev Accuracy: 0.2500; Dev Precision: 0.2500; Dev Recall: 1.0000; Dev Loss:0.8673\n",
      "Epoch 2: Dev Accuracy: 0.2500; Dev Precision: 0.2500; Dev Recall: 1.0000; Dev Loss:0.8675\n",
      "Epoch 3: Dev Accuracy: 0.2500; Dev Precision: 0.2500; Dev Recall: 1.0000; Dev Loss:0.8678\n",
      "Epoch 4: Dev Accuracy: 0.2500; Dev Precision: 0.2500; Dev Recall: 1.0000; Dev Loss:0.8678\n",
      "Epoch 5: Dev Accuracy: 0.2500; Dev Precision: 0.2500; Dev Recall: 1.0000; Dev Loss:0.8675\n",
      "Epoch 6: Dev Accuracy: 0.2500; Dev Precision: 0.2500; Dev Recall: 1.0000; Dev Loss:0.8682\n",
      "Epoch 7: Dev Accuracy: 0.2500; Dev Precision: 0.2500; Dev Recall: 1.0000; Dev Loss:0.8684\n",
      "Epoch 8: Dev Accuracy: 0.2500; Dev Precision: 0.2500; Dev Recall: 1.0000; Dev Loss:0.8690\n",
      "Epoch 9: Dev Accuracy: 0.2500; Dev Precision: 0.2500; Dev Recall: 1.0000; Dev Loss:0.8689\n",
      "--------------------\n",
      "\n",
      "Architecture #2\n",
      "--------------------\n",
      "Epoch 0: Dev Accuracy: 0.2500; Dev Precision: 0.2500; Dev Recall: 1.0000; Dev Loss:0.8600\n",
      "Epoch 1: Dev Accuracy: 0.7500; Dev Precision: nan; Dev Recall: 0.0000; Dev Loss:0.8531\n",
      "Epoch 2: Dev Accuracy: 0.2500; Dev Precision: 0.0000; Dev Recall: 0.0000; Dev Loss:0.9589\n",
      "Epoch 3: Dev Accuracy: 0.5000; Dev Precision: 0.3333; Dev Recall: 1.0000; Dev Loss:0.7681\n",
      "Epoch 4: Dev Accuracy: 0.5000; Dev Precision: 0.3333; Dev Recall: 1.0000; Dev Loss:0.8086\n",
      "Epoch 5: Dev Accuracy: 0.2500; Dev Precision: 0.0000; Dev Recall: 0.0000; Dev Loss:1.0353\n",
      "Epoch 6: Dev Accuracy: 0.2500; Dev Precision: 0.0000; Dev Recall: 0.0000; Dev Loss:0.9769\n",
      "Epoch 7: Dev Accuracy: 0.7500; Dev Precision: 0.5000; Dev Recall: 1.0000; Dev Loss:0.7129\n",
      "Epoch 8: Dev Accuracy: 0.2500; Dev Precision: 0.0000; Dev Recall: 0.0000; Dev Loss:0.9277\n",
      "Epoch 9: Dev Accuracy: 0.5000; Dev Precision: 0.3333; Dev Recall: 1.0000; Dev Loss:0.8665\n",
      "--------------------\n",
      "\n",
      "Architecture #3\n",
      "--------------------\n",
      "Epoch 0: Dev Accuracy: 0.2500; Dev Precision: 0.2500; Dev Recall: 1.0000; Dev Loss:0.8701\n",
      "Epoch 1: Dev Accuracy: 0.2500; Dev Precision: 0.2500; Dev Recall: 1.0000; Dev Loss:0.8690\n",
      "Epoch 2: Dev Accuracy: 0.2500; Dev Precision: 0.2500; Dev Recall: 1.0000; Dev Loss:0.8700\n",
      "Epoch 3: Dev Accuracy: 0.2500; Dev Precision: 0.2500; Dev Recall: 1.0000; Dev Loss:0.8701\n",
      "Epoch 4: Dev Accuracy: 0.2500; Dev Precision: 0.2500; Dev Recall: 1.0000; Dev Loss:0.8696\n",
      "Epoch 5: Dev Accuracy: 0.2500; Dev Precision: 0.2500; Dev Recall: 1.0000; Dev Loss:0.8698\n",
      "Epoch 6: Dev Accuracy: 0.2500; Dev Precision: 0.2500; Dev Recall: 1.0000; Dev Loss:0.8698\n",
      "Epoch 7: Dev Accuracy: 0.2500; Dev Precision: 0.2500; Dev Recall: 1.0000; Dev Loss:0.8689\n",
      "Epoch 8: Dev Accuracy: 0.2500; Dev Precision: 0.2500; Dev Recall: 1.0000; Dev Loss:0.8691\n",
      "Epoch 9: Dev Accuracy: 0.2500; Dev Precision: 0.2500; Dev Recall: 1.0000; Dev Loss:0.8685\n",
      "--------------------\n",
      "\n",
      "Architecture #4\n",
      "--------------------\n",
      "Epoch 0: Dev Accuracy: 0.7500; Dev Precision: nan; Dev Recall: 0.0000; Dev Loss:0.8480\n",
      "Epoch 1: Dev Accuracy: 0.7500; Dev Precision: nan; Dev Recall: 0.0000; Dev Loss:0.8477\n",
      "Epoch 2: Dev Accuracy: 0.5000; Dev Precision: 0.0000; Dev Recall: 0.0000; Dev Loss:0.8598\n",
      "Epoch 3: Dev Accuracy: 0.5000; Dev Precision: 0.0000; Dev Recall: 0.0000; Dev Loss:0.8869\n",
      "Epoch 4: Dev Accuracy: 0.5000; Dev Precision: 0.0000; Dev Recall: 0.0000; Dev Loss:0.8895\n",
      "Epoch 5: Dev Accuracy: 0.5000; Dev Precision: 0.0000; Dev Recall: 0.0000; Dev Loss:0.9158\n",
      "Epoch 6: Dev Accuracy: 0.5000; Dev Precision: 0.0000; Dev Recall: 0.0000; Dev Loss:0.9251\n",
      "Epoch 7: Dev Accuracy: 0.5000; Dev Precision: 0.0000; Dev Recall: 0.0000; Dev Loss:0.9323\n",
      "Epoch 8: Dev Accuracy: 0.2500; Dev Precision: 0.0000; Dev Recall: 0.0000; Dev Loss:0.9134\n",
      "Epoch 9: Dev Accuracy: 0.2500; Dev Precision: 0.0000; Dev Recall: 0.0000; Dev Loss:0.9935\n",
      "--------------------\n",
      "\n",
      "Architecture #5\n",
      "--------------------\n",
      "Epoch 0: Dev Accuracy: 0.7500; Dev Precision: nan; Dev Recall: 0.0000; Dev Loss:0.8279\n",
      "Epoch 1: Dev Accuracy: 0.7500; Dev Precision: nan; Dev Recall: 0.0000; Dev Loss:0.8282\n",
      "Epoch 2: Dev Accuracy: 0.7500; Dev Precision: nan; Dev Recall: 0.0000; Dev Loss:0.8286\n",
      "Epoch 3: Dev Accuracy: 0.7500; Dev Precision: nan; Dev Recall: 0.0000; Dev Loss:0.8293\n",
      "Epoch 4: Dev Accuracy: 0.7500; Dev Precision: nan; Dev Recall: 0.0000; Dev Loss:0.8296\n",
      "Epoch 5: Dev Accuracy: 0.7500; Dev Precision: nan; Dev Recall: 0.0000; Dev Loss:0.8304\n",
      "Epoch 6: Dev Accuracy: 0.7500; Dev Precision: nan; Dev Recall: 0.0000; Dev Loss:0.8308\n",
      "Epoch 7: Dev Accuracy: 0.7500; Dev Precision: nan; Dev Recall: 0.0000; Dev Loss:0.8316\n",
      "Epoch 8: Dev Accuracy: 0.7500; Dev Precision: nan; Dev Recall: 0.0000; Dev Loss:0.8318\n",
      "Epoch 9: Dev Accuracy: 0.7500; Dev Precision: nan; Dev Recall: 0.0000; Dev Loss:0.8320\n",
      "--------------------\n",
      "\n",
      "Architecture #6\n",
      "--------------------\n",
      "Epoch 0: Dev Accuracy: 0.7500; Dev Precision: nan; Dev Recall: 0.0000; Dev Loss:0.8332\n",
      "Epoch 1: Dev Accuracy: 0.5000; Dev Precision: 0.0000; Dev Recall: 0.0000; Dev Loss:0.8368\n",
      "Epoch 2: Dev Accuracy: 0.2500; Dev Precision: 0.2500; Dev Recall: 1.0000; Dev Loss:0.9630\n",
      "Epoch 3: Dev Accuracy: 0.2500; Dev Precision: 0.2500; Dev Recall: 1.0000; Dev Loss:0.9082\n",
      "Epoch 4: Dev Accuracy: 0.5000; Dev Precision: 0.3333; Dev Recall: 1.0000; Dev Loss:0.9429\n",
      "Epoch 5: Dev Accuracy: 0.5000; Dev Precision: 0.0000; Dev Recall: 0.0000; Dev Loss:0.9594\n",
      "Epoch 6: Dev Accuracy: 0.5000; Dev Precision: 0.0000; Dev Recall: 0.0000; Dev Loss:0.8438\n",
      "Epoch 7: Dev Accuracy: 0.5000; Dev Precision: 0.0000; Dev Recall: 0.0000; Dev Loss:0.8328\n",
      "Epoch 8: Dev Accuracy: 0.2500; Dev Precision: 0.0000; Dev Recall: 0.0000; Dev Loss:0.8943\n",
      "Epoch 9: Dev Accuracy: 0.7500; Dev Precision: 0.5000; Dev Recall: 1.0000; Dev Loss:0.7165\n",
      "--------------------\n",
      "\n",
      "Architecture #7\n",
      "--------------------\n",
      "Epoch 0: Dev Accuracy: 0.2500; Dev Precision: 0.2500; Dev Recall: 1.0000; Dev Loss:0.8526\n",
      "Epoch 1: Dev Accuracy: 0.2500; Dev Precision: 0.2500; Dev Recall: 1.0000; Dev Loss:0.8524\n",
      "Epoch 2: Dev Accuracy: 0.2500; Dev Precision: 0.2500; Dev Recall: 1.0000; Dev Loss:0.8524\n",
      "Epoch 3: Dev Accuracy: 0.2500; Dev Precision: 0.2500; Dev Recall: 1.0000; Dev Loss:0.8520\n",
      "Epoch 4: Dev Accuracy: 0.2500; Dev Precision: 0.2500; Dev Recall: 1.0000; Dev Loss:0.8517\n",
      "Epoch 5: Dev Accuracy: 0.2500; Dev Precision: 0.2500; Dev Recall: 1.0000; Dev Loss:0.8517\n",
      "Epoch 6: Dev Accuracy: 0.2500; Dev Precision: 0.2500; Dev Recall: 1.0000; Dev Loss:0.8520\n",
      "Epoch 7: Dev Accuracy: 0.2500; Dev Precision: 0.2500; Dev Recall: 1.0000; Dev Loss:0.8524\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-2e045283c0ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0mtm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainingModule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPOS_WEIGHT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUSE_CUDA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m     \u001b[0mbest_models\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_it\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_it\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_model\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbest_models\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/advanced-ml-project/modeling/training.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(self, train_iterator, dev_iterator)\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0mbest_model_rec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_iterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m             \u001b[0mdev_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_prec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_rec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdev_iterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             print(f\"Epoch {epoch}: Dev Accuracy: {dev_acc:.4f}; Dev Precision:\",\n",
      "\u001b[0;32m~/advanced-ml-project/modeling/training.py\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m     97\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m             \u001b[0mepoch_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m             \u001b[0mepoch_acc\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m             \u001b[0mepoch_prec\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mprecision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Store training results\n",
    "df = pd.DataFrame(columns=['architecture', 'model_type', 'embeddings',\n",
    "                           'hidden', 'num_layers', 'dropouts',\n",
    "                           'bidirectional', 'learning_rate', 'epochs',\n",
    "                           'dev_acc', 'dev_prec', 'dev_recall',\n",
    "                           'metric'])\n",
    "\n",
    "# Model architecture parameters\n",
    "RNN_TYPES = ['RNN', 'LSTM']\n",
    "INPUT_DIM = len(TEXT.vocab)\n",
    "EMBEDDING_SIZE = TEXT.vocab.vectors.size(1)\n",
    "HIDDEN_SIZES = [1/3, 2/3]\n",
    "OUTPUT_SIZE = 1\n",
    "NUM_LAYERS = [1, 2]\n",
    "DROPOUTS = [0.5, 0.75]\n",
    "BIDIRECTIONALS = [False, True]\n",
    "PADDING_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
    "\n",
    "# Model training hyperparameters\n",
    "LEARNING_RATE = [0.01, 0.0001]\n",
    "train_len = 0\n",
    "train_pos = 0\n",
    "for batch in train_it:\n",
    "    train_len += len(batch.decision_binary)\n",
    "    train_pos += batch.decision_binary.sum().item()\n",
    "POS_WEIGHT = torch.tensor([(train_len - train_pos) / train_pos])\n",
    "if USE_CUDA:\n",
    "    POS_WEIGHT = POS_WEIGHT.cuda()\n",
    "EPOCHS = 10\n",
    "\n",
    "# Iterator over various model parameters\n",
    "param_iter = product (RNN_TYPES, HIDDEN_SIZES, NUM_LAYERS,\n",
    "                      DROPOUTS, BIDIRECTIONALS, LEARNING_RATE)\n",
    "\n",
    "# Magic loop\n",
    "best_acc = (None, None)\n",
    "best_rec = (None, None)\n",
    "best_prec = (None, None)\n",
    "for i, (rnn_type, hidden_size, num_layers, dropout, bidirectional,\\\n",
    "    lr) in enumerate(param_iter):\n",
    "    print(f'Architecture #{i}\\n' + '-' * 20)\n",
    "    hidden_dim = int(hidden_size * EMBEDDING_SIZE)\n",
    "    model = RNNPtEmbeds(rnn_type, INPUT_DIM, EMBEDDING_SIZE,\n",
    "                        hidden_dim, OUTPUT_SIZE, num_layers,\n",
    "                        dropout, bidirectional, PADDING_IDX)\n",
    "    \n",
    "    tm = TrainingModule(model, lr, POS_WEIGHT, USE_CUDA, EPOCHS)\n",
    "    \n",
    "    best_models = tm.train_model(train_it, val_it)\n",
    "    \n",
    "    for metric, best_model in best_models.items():\n",
    "        row = [i, rnn_type, 'Law2Vec', hidden_size, num_layers, dropout,\n",
    "               bidirectional, lr, EPOCHS, best_model.accuracy,\n",
    "               best_model.precision, best_model.recall, metric]\n",
    "        df.loc[len(df)] = row\n",
    "        if best_acc[0] is None or best_model.accuracy > best_acc[1]:\n",
    "            best_acc = (copy.deepcopy(best_model.model), best_model.accuracy)\n",
    "        if best_rec[0] is None or best_model.recall > best_rec[1]:\n",
    "            best_rec = (copy.deepcopy(best_model.model), best_model.recall)\n",
    "        if best_prec[0] is None or isnan(best_prec[1]) or\\\n",
    "           best_model.precision > best_prec[1]:\n",
    "            best_prec = (copy.deepcopy(best_model.model), best_model.precision)\n",
    "    \n",
    "    print('-' * 20 + '\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save results of model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_PREFIX = '../results/RNNLaw2Vec_'\n",
    "df.to_csv(f'{SAVE_PREFIX}models.csv')\n",
    "torch.save(best_acc[0], f'{SAVE_PREFIX}best_acc.pt')\n",
    "torch.save(best_rec[0], f'{SAVE_PREFIX}best_rec.pt')\n",
    "torch.save(best_prec[0], f'{SAVE_PREFIX}best_prec.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confirming embeddings have not been trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "medicare_tensor = torch.LongTensor([TEXT.vocab.stoi['medicare']])\n",
    "if USE_CUDA:\n",
    "    medicare_tensor = medicare_tensor.cuda()\n",
    "model.embedding(medicare_tensor)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adv-ml",
   "language": "python",
   "name": "adv-ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
