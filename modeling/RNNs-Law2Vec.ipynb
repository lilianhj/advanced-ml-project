{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNNs with Law2Vec embeddings\n",
    "\n",
    "## Importing data, pre-trained embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from itertools import product\n",
    "from numpy import isnan\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchtext.data as data\n",
    "import torchtext.vocab as vocab\n",
    "import sys\n",
    "\n",
    "sys.path.append('../data_pipeline/')\n",
    "import preprocessing as pre\n",
    "from training import TrainingModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/bf-repo/preprocessing.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  apply(lambda x: x[0: 1000000])\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data, val_data, TEXT, LABEL = pre.get_data(\n",
    "    'train_small.csv', 'val_small.csv', 'test_small.csv', 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_CUDA = torch.cuda.is_available()\n",
    "\n",
    "vectors = vocab.Vectors('../embeds/Law2Vec.100d.txt') # Law2Vec available from https://archive.org/details/Law2Vec\n",
    "\n",
    "TEXT.build_vocab(train_data, vectors=vectors,\n",
    "                 unk_init = torch.Tensor.normal_)\n",
    "LABEL.build_vocab(train_data)\n",
    "\n",
    "BATCH_SIZE = 5\n",
    "\n",
    "train_it, test_it, val_it = data.BucketIterator.splits(\n",
    "    (train_data, test_data, val_data), \n",
    "    batch_size = BATCH_SIZE,\n",
    "    sort_key=lambda x: len(x.alj_text),\n",
    "    sort_within_batch=True,\n",
    "    device = torch.device('cuda' if USE_CUDA else 'cpu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking pretrained vectors have been applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.6415, -0.5367, -0.3537, -0.0634, -0.1798,  0.0626, -0.1836, -0.2705,\n",
       "         0.2504,  0.5061,  0.4746, -0.2351, -0.0465,  0.3184,  0.8974,  0.0470,\n",
       "        -0.2594,  0.3485, -0.3356,  0.1163,  0.2207,  0.2707,  0.4748,  0.1122,\n",
       "        -0.1188, -0.0790,  0.4377, -0.4711,  0.1401, -0.0234, -0.2009, -0.2143,\n",
       "         0.1335, -0.4407,  0.4077, -0.0634,  0.5104,  0.1820, -0.4729, -0.1758,\n",
       "         0.6194,  0.5708, -0.3034, -0.3658,  0.1609,  0.0753, -0.2024, -0.1472,\n",
       "         0.0665,  0.1823,  0.3091, -0.0913,  0.2495,  0.0777, -0.1873, -0.5850,\n",
       "        -0.3243,  0.1540, -0.5094,  0.6227,  0.1163, -0.6202, -0.4416, -0.3509,\n",
       "        -0.5760, -0.4837, -0.6283,  0.0938,  0.3528, -0.0674, -0.7097, -0.2053,\n",
       "        -0.6007, -0.1306,  0.0146, -0.0830,  0.5486, -0.2328, -0.3193,  0.1496,\n",
       "        -0.1635,  0.0755, -0.2594, -0.0317,  0.1249, -0.5599,  0.0722, -0.0369,\n",
       "         0.3139,  0.0102, -0.3353,  0.1142, -0.1163,  0.1505,  0.0952,  0.0206,\n",
       "        -0.0733, -0.4851,  0.4995,  0.0404])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors['medicare']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.6415, -0.5367, -0.3537, -0.0634, -0.1798,  0.0626, -0.1836, -0.2705,\n",
       "         0.2504,  0.5061,  0.4746, -0.2351, -0.0465,  0.3184,  0.8974,  0.0470,\n",
       "        -0.2594,  0.3485, -0.3356,  0.1163,  0.2207,  0.2707,  0.4748,  0.1122,\n",
       "        -0.1188, -0.0790,  0.4377, -0.4711,  0.1401, -0.0234, -0.2009, -0.2143,\n",
       "         0.1335, -0.4407,  0.4077, -0.0634,  0.5104,  0.1820, -0.4729, -0.1758,\n",
       "         0.6194,  0.5708, -0.3034, -0.3658,  0.1609,  0.0753, -0.2024, -0.1472,\n",
       "         0.0665,  0.1823,  0.3091, -0.0913,  0.2495,  0.0777, -0.1873, -0.5850,\n",
       "        -0.3243,  0.1540, -0.5094,  0.6227,  0.1163, -0.6202, -0.4416, -0.3509,\n",
       "        -0.5760, -0.4837, -0.6283,  0.0938,  0.3528, -0.0674, -0.7097, -0.2053,\n",
       "        -0.6007, -0.1306,  0.0146, -0.0830,  0.5486, -0.2328, -0.3193,  0.1496,\n",
       "        -0.1635,  0.0755, -0.2594, -0.0317,  0.1249, -0.5599,  0.0722, -0.0369,\n",
       "         0.3139,  0.0102, -0.3353,  0.1142, -0.1163,  0.1505,  0.0952,  0.0206,\n",
       "        -0.0733, -0.4851,  0.4995,  0.0404])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT.vocab.vectors[TEXT.vocab.stoi['medicare']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNPtEmbeds(nn.Module):\n",
    "    \n",
    "    def __init__(self, rnn_type, input_size, embedding_size,\n",
    "                 hidden_size, output_size, num_layers,\n",
    "                 dropout, bidirectional, padding_idx):\n",
    "    \n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding\\\n",
    "                           .from_pretrained(TEXT.vocab.vectors)\n",
    "\n",
    "        self.rnn = getattr(nn, rnn_type.upper())\\\n",
    "                          (embedding_size, hidden_size, num_layers,\n",
    "                           dropout=(dropout if num_layers > 1 else 0),\n",
    "                           bidirectional=bidirectional)\n",
    "        \n",
    "        self.leakyrelu = nn.LeakyReLU()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        linear_inp = (hidden_size * 2 if bidirectional else hidden_size)\n",
    "        self.linear = nn.Linear(linear_inp, output_size)\n",
    "             \n",
    "    def forward(self, input):\n",
    "        embed = self.embedding(input)\n",
    "        rnn_out, hidden = self.rnn(embed)\n",
    "        rnn_out = rnn_out[-1]\n",
    "        rnn_out = self.leakyrelu(rnn_out)\n",
    "        rnn_out = self.dropout(rnn_out)\n",
    "        linear_out = self.linear(rnn_out)\n",
    "        return linear_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Architecture #0\n",
      "--------------------\n",
      "Epoch 0: Dev Accuracy: 0.7500; Dev Precision: nan; Dev Recall: 0.0000; Dev Loss:0.8611\n",
      "Epoch 1: Dev Accuracy: 0.5000; Dev Precision: 0.3333; Dev Recall: 1.0000; Dev Loss:0.8672\n",
      "Epoch 2: Dev Accuracy: 0.7500; Dev Precision: nan; Dev Recall: 0.0000; Dev Loss:0.8560\n",
      "Epoch 3: Dev Accuracy: 0.7500; Dev Precision: nan; Dev Recall: 0.0000; Dev Loss:0.8528\n",
      "Epoch 4: Dev Accuracy: 0.7500; Dev Precision: nan; Dev Recall: 0.0000; Dev Loss:0.8442\n",
      "Epoch 5: Dev Accuracy: 0.7500; Dev Precision: nan; Dev Recall: 0.0000; Dev Loss:0.8404\n",
      "Epoch 6: Dev Accuracy: 0.7500; Dev Precision: nan; Dev Recall: 0.0000; Dev Loss:0.8241\n",
      "Epoch 7: Dev Accuracy: 0.7500; Dev Precision: nan; Dev Recall: 0.0000; Dev Loss:0.8229\n",
      "Epoch 8: Dev Accuracy: 0.5000; Dev Precision: 0.3333; Dev Recall: 1.0000; Dev Loss:0.8166\n",
      "Epoch 9: Dev Accuracy: 0.5000; Dev Precision: 0.3333; Dev Recall: 1.0000; Dev Loss:0.8022\n",
      "Epoch 10: Dev Accuracy: 0.7500; Dev Precision: nan; Dev Recall: 0.0000; Dev Loss:0.7861\n",
      "Epoch 11: Dev Accuracy: 0.5000; Dev Precision: 0.3333; Dev Recall: 1.0000; Dev Loss:0.7994\n",
      "Epoch 12: Dev Accuracy: 0.5000; Dev Precision: 0.3333; Dev Recall: 1.0000; Dev Loss:0.8086\n",
      "Epoch 13: Dev Accuracy: 0.5000; Dev Precision: 0.0000; Dev Recall: 0.0000; Dev Loss:0.8044\n",
      "Epoch 14: Dev Accuracy: 0.7500; Dev Precision: nan; Dev Recall: 0.0000; Dev Loss:0.7970\n",
      "--------------------\n",
      "\n",
      "Architecture #1\n",
      "--------------------\n",
      "Epoch 0: Dev Accuracy: 0.7500; Dev Precision: nan; Dev Recall: 0.0000; Dev Loss:0.8784\n",
      "Epoch 1: Dev Accuracy: 0.7500; Dev Precision: nan; Dev Recall: 0.0000; Dev Loss:0.8782\n",
      "Epoch 2: Dev Accuracy: 0.7500; Dev Precision: nan; Dev Recall: 0.0000; Dev Loss:0.8780\n",
      "Epoch 3: Dev Accuracy: 0.7500; Dev Precision: nan; Dev Recall: 0.0000; Dev Loss:0.8778\n",
      "Epoch 4: Dev Accuracy: 0.7500; Dev Precision: nan; Dev Recall: 0.0000; Dev Loss:0.8776\n",
      "Epoch 5: Dev Accuracy: 0.7500; Dev Precision: nan; Dev Recall: 0.0000; Dev Loss:0.8774\n",
      "Epoch 6: Dev Accuracy: 0.7500; Dev Precision: nan; Dev Recall: 0.0000; Dev Loss:0.8772\n",
      "Epoch 7: Dev Accuracy: 0.7500; Dev Precision: nan; Dev Recall: 0.0000; Dev Loss:0.8769\n",
      "Epoch 8: Dev Accuracy: 0.7500; Dev Precision: nan; Dev Recall: 0.0000; Dev Loss:0.8767\n",
      "Epoch 9: Dev Accuracy: 0.7500; Dev Precision: nan; Dev Recall: 0.0000; Dev Loss:0.8766\n",
      "Epoch 10: Dev Accuracy: 0.7500; Dev Precision: nan; Dev Recall: 0.0000; Dev Loss:0.8764\n",
      "Epoch 11: Dev Accuracy: 0.7500; Dev Precision: nan; Dev Recall: 0.0000; Dev Loss:0.8761\n",
      "Epoch 12: Dev Accuracy: 0.7500; Dev Precision: nan; Dev Recall: 0.0000; Dev Loss:0.8758\n",
      "Epoch 13: Dev Accuracy: 0.7500; Dev Precision: nan; Dev Recall: 0.0000; Dev Loss:0.8755\n",
      "Epoch 14: Dev Accuracy: 0.7500; Dev Precision: nan; Dev Recall: 0.0000; Dev Loss:0.8751\n",
      "--------------------\n",
      "\n",
      "Architecture #2\n",
      "--------------------\n",
      "Epoch 0: Dev Accuracy: 0.5000; Dev Precision: 0.3333; Dev Recall: 1.0000; Dev Loss:0.8744\n",
      "Epoch 1: Dev Accuracy: 0.7500; Dev Precision: nan; Dev Recall: 0.0000; Dev Loss:0.8338\n",
      "Epoch 2: Dev Accuracy: 0.7500; Dev Precision: nan; Dev Recall: 0.0000; Dev Loss:0.8151\n",
      "Epoch 3: Dev Accuracy: 0.5000; Dev Precision: 0.3333; Dev Recall: 1.0000; Dev Loss:0.8100\n",
      "Epoch 4: Dev Accuracy: 0.5000; Dev Precision: 0.3333; Dev Recall: 1.0000; Dev Loss:0.7891\n",
      "Epoch 5: Dev Accuracy: 0.7500; Dev Precision: nan; Dev Recall: 0.0000; Dev Loss:0.7829\n",
      "Epoch 6: Dev Accuracy: 0.7500; Dev Precision: nan; Dev Recall: 0.0000; Dev Loss:0.7770\n",
      "Epoch 7: Dev Accuracy: 0.5000; Dev Precision: 0.3333; Dev Recall: 1.0000; Dev Loss:0.7865\n",
      "Epoch 8: Dev Accuracy: 0.5000; Dev Precision: 0.3333; Dev Recall: 1.0000; Dev Loss:0.7893\n",
      "Epoch 9: Dev Accuracy: 0.5000; Dev Precision: 0.3333; Dev Recall: 1.0000; Dev Loss:0.7754\n",
      "Epoch 10: Dev Accuracy: 0.5000; Dev Precision: 0.3333; Dev Recall: 1.0000; Dev Loss:0.7696\n",
      "Epoch 11: Dev Accuracy: 0.5000; Dev Precision: 0.3333; Dev Recall: 1.0000; Dev Loss:0.7751\n",
      "Epoch 12: Dev Accuracy: 0.7500; Dev Precision: nan; Dev Recall: 0.0000; Dev Loss:0.8366\n",
      "Epoch 13: Dev Accuracy: 0.7500; Dev Precision: nan; Dev Recall: 0.0000; Dev Loss:0.8542\n",
      "Epoch 14: Dev Accuracy: 0.5000; Dev Precision: 0.0000; Dev Recall: 0.0000; Dev Loss:0.9514\n",
      "--------------------\n",
      "\n",
      "Architecture #3\n",
      "--------------------\n",
      "Epoch 0: Dev Accuracy: 0.5000; Dev Precision: 0.3333; Dev Recall: 1.0000; Dev Loss:0.8919\n",
      "Epoch 1: Dev Accuracy: 0.5000; Dev Precision: 0.3333; Dev Recall: 1.0000; Dev Loss:0.8906\n",
      "Epoch 2: Dev Accuracy: 0.5000; Dev Precision: 0.3333; Dev Recall: 1.0000; Dev Loss:0.8897\n",
      "Epoch 3: Dev Accuracy: 0.5000; Dev Precision: 0.3333; Dev Recall: 1.0000; Dev Loss:0.8890\n",
      "Epoch 4: Dev Accuracy: 0.5000; Dev Precision: 0.3333; Dev Recall: 1.0000; Dev Loss:0.8881\n",
      "Epoch 5: Dev Accuracy: 0.5000; Dev Precision: 0.3333; Dev Recall: 1.0000; Dev Loss:0.8876\n",
      "Epoch 6: Dev Accuracy: 0.5000; Dev Precision: 0.3333; Dev Recall: 1.0000; Dev Loss:0.8864\n",
      "Epoch 7: Dev Accuracy: 0.5000; Dev Precision: 0.3333; Dev Recall: 1.0000; Dev Loss:0.8858\n",
      "Epoch 8: Dev Accuracy: 0.5000; Dev Precision: 0.3333; Dev Recall: 1.0000; Dev Loss:0.8848\n",
      "Epoch 9: Dev Accuracy: 0.5000; Dev Precision: 0.3333; Dev Recall: 1.0000; Dev Loss:0.8841\n",
      "Epoch 10: Dev Accuracy: 0.5000; Dev Precision: 0.3333; Dev Recall: 1.0000; Dev Loss:0.8837\n",
      "Epoch 11: Dev Accuracy: 0.5000; Dev Precision: 0.3333; Dev Recall: 1.0000; Dev Loss:0.8834\n",
      "Epoch 12: Dev Accuracy: 0.5000; Dev Precision: 0.3333; Dev Recall: 1.0000; Dev Loss:0.8824\n",
      "Epoch 13: Dev Accuracy: 0.5000; Dev Precision: 0.3333; Dev Recall: 1.0000; Dev Loss:0.8822\n",
      "Epoch 14: Dev Accuracy: 0.5000; Dev Precision: 0.3333; Dev Recall: 1.0000; Dev Loss:0.8815\n",
      "--------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Store training results\n",
    "df = pd.DataFrame(columns=['architecture', 'model_type', 'embeddings',\n",
    "                           'hidden', 'num_layers', 'dropouts',\n",
    "                           'bidirectional', 'learning_rate', 'epochs',\n",
    "                           'dev_acc', 'dev_prec', 'dev_recall',\n",
    "                           'metric'])\n",
    "\n",
    "# Model architecture parameters\n",
    "RNN_TYPES = ['RNN', 'LSTM']\n",
    "INPUT_DIM = len(TEXT.vocab)\n",
    "EMBEDDING_SIZE = TEXT.vocab.vectors.size(1)\n",
    "HIDDEN_SIZES = [1/3, 2/3]\n",
    "OUTPUT_SIZE = 1\n",
    "NUM_LAYERS = [1, 2]\n",
    "DROPOUTS = [0.5, 0.75]\n",
    "BIDIRECTIONALS = [False, True]\n",
    "PADDING_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
    "\n",
    "# Model training hyperparameters\n",
    "LEARNING_RATE = [0.01, 0.0001]\n",
    "train_len = 0\n",
    "train_pos = 0\n",
    "for batch in train_it:\n",
    "    train_len += len(batch.decision_binary)\n",
    "    train_pos += batch.decision_binary.sum().item()\n",
    "POS_WEIGHT = torch.tensor([(train_len - train_pos) / train_pos])\n",
    "if USE_CUDA:\n",
    "    POS_WEIGHT = POS_WEIGHT.cuda()\n",
    "EPOCHS = 10\n",
    "\n",
    "# Iterator over various model parameters\n",
    "param_iter = product (RNN_TYPES, HIDDEN_SIZES, NUM_LAYERS,\n",
    "                      DROPOUTS, BIDIRECTIONALS, LEARNING_RATE)\n",
    "\n",
    "# Magic loop\n",
    "best_acc = (None, None)\n",
    "best_rec = (None, None)\n",
    "best_prec = (None, None)\n",
    "for i, (rnn_type, hidden_size, num_layers, dropout, bidirectional,\\\n",
    "    lr) in enumerate(param_iter):\n",
    "    print(f'Architecture #{i}\\n' + '-' * 20)\n",
    "    hidden_dim = int(hidden_size * EMBEDDING_SIZE)\n",
    "    model = RNNPtEmbeds(rnn_type, INPUT_DIM, EMBEDDING_SIZE,\n",
    "                        hidden_dim, OUTPUT_SIZE, num_layers,\n",
    "                        dropout, bidirectional, PADDING_IDX)\n",
    "    \n",
    "    tm = TrainingModule(model, lr, POS_WEIGHT, USE_CUDA, EPOCHS)\n",
    "    \n",
    "    best_models = tm.train_model(train_it, val_it)\n",
    "    \n",
    "    for metric, best_model in best_models.items():\n",
    "        row = [i, rnn_type, 'Law2Vec', hidden_size, num_layers, dropout,\n",
    "               bidirectional, lr, EPOCHS, best_model.accuracy,\n",
    "               best_model.precision, best_model.recall, metric]\n",
    "        df.loc[len(df)] = row\n",
    "        if best_acc[0] is None or best_model.accuracy > best_acc[1]:\n",
    "            best_acc = (copy.deepcopy(best_model.model), best_model.accuracy)\n",
    "        if best_rec[0] is None or best_model.recall > best_rec[1]:\n",
    "            best_rec = (copy.deepcopy(best_model.model), best_model.recall)\n",
    "        if best_prec[0] is None or isnan(best_prec[1]) or\\\n",
    "           best_model.precision > best_prec[1]:\n",
    "            best_prec = (copy.deepcopy(best_model.model), best_model.precision)\n",
    "    \n",
    "    print('-' * 20 + '\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save results of model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_PREFIX = '../results/RNNLaw2Vec_'\n",
    "df.to_csv(f'{SAVE_PREFIX}models.csv')\n",
    "torch.save(best_acc[0], f'{SAVE_PREFIX}best_acc.pt')\n",
    "torch.save(best_rec[0], f'{SAVE_PREFIX}best_rec.pt')\n",
    "torch.save(best_prec[0], f'{SAVE_PREFIX}best_prec.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confirming embeddings have not been trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.6415, -0.5367, -0.3537, -0.0634, -0.1798,  0.0626, -0.1836, -0.2705,\n",
       "          0.2504,  0.5061,  0.4746, -0.2351, -0.0465,  0.3184,  0.8974,  0.0470,\n",
       "         -0.2594,  0.3485, -0.3356,  0.1163,  0.2207,  0.2707,  0.4748,  0.1122,\n",
       "         -0.1188, -0.0790,  0.4377, -0.4711,  0.1401, -0.0234, -0.2009, -0.2143,\n",
       "          0.1335, -0.4407,  0.4077, -0.0634,  0.5104,  0.1820, -0.4729, -0.1758,\n",
       "          0.6194,  0.5708, -0.3034, -0.3658,  0.1609,  0.0753, -0.2024, -0.1472,\n",
       "          0.0665,  0.1823,  0.3091, -0.0913,  0.2495,  0.0777, -0.1873, -0.5850,\n",
       "         -0.3243,  0.1540, -0.5094,  0.6227,  0.1163, -0.6202, -0.4416, -0.3509,\n",
       "         -0.5760, -0.4837, -0.6283,  0.0938,  0.3528, -0.0674, -0.7097, -0.2053,\n",
       "         -0.6007, -0.1306,  0.0146, -0.0830,  0.5486, -0.2328, -0.3193,  0.1496,\n",
       "         -0.1635,  0.0755, -0.2594, -0.0317,  0.1249, -0.5599,  0.0722, -0.0369,\n",
       "          0.3139,  0.0102, -0.3353,  0.1142, -0.1163,  0.1505,  0.0952,  0.0206,\n",
       "         -0.0733, -0.4851,  0.4995,  0.0404]], device='cuda:0')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medicare_tensor = torch.LongTensor([TEXT.vocab.stoi['medicare']])\n",
    "if USE_CUDA:\n",
    "    medicare_tensor = medicare_tensor.cuda()\n",
    "model.embedding(medicare_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adv-ml",
   "language": "python",
   "name": "adv-ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
