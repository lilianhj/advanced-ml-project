{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNNs with custom embeddings\n",
    "\n",
    "## Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "from itertools import product\n",
    "from numpy import isnan\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchtext.data as data\n",
    "\n",
    "import preprocessing as pre\n",
    "from training import TrainingModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected!\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data, val_data, TEXT, LABEL = pre.get_data(\n",
    "    'train_small.csv', 'val_small.csv', 'test_small.csv', 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_CUDA = torch.cuda.is_available()\n",
    "\n",
    "TEXT.build_vocab(train_data)\n",
    "LABEL.build_vocab(train_data)\n",
    "\n",
    "train_it, test_it, val_it = data.BucketIterator.splits(\n",
    "    (train_data, test_data, val_data), \n",
    "    batch_size = BATCH_SIZE,\n",
    "    sort_key=lambda x: len(x.alj_text),\n",
    "    sort_within_batch=True,\n",
    "    device = torch.device('cuda' if USE_CUDA else 'cpu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, rnn_type, input_size, embedding_size,\n",
    "                 hidden_size, output_size, num_layers, dropout,\n",
    "                 bidirectional, padding_idx):\n",
    "    \n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(input_size, embedding_size,\n",
    "                                      padding_idx=padding_idx)\n",
    "        \n",
    "        self.rnn = getattr(nn, rnn_type.upper())\\\n",
    "                          (embedding_size, hidden_size, num_layers,\n",
    "                           dropout=(dropout if num_layers > 1 else 0),\n",
    "                           bidirectional=bidirectional)\n",
    "        \n",
    "        self.leakyrelu = nn.LeakyReLU()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        linear_inp = (hidden_size * 2 if bidirectional else hidden_size)\n",
    "        self.linear = nn.Linear(linear_inp, output_size)\n",
    "             \n",
    "    def forward(self, input):\n",
    "        embed = self.embedding(input)\n",
    "        rnn_out, hidden = self.rnn(embed)\n",
    "        rnn_out = rnn_out[-1]\n",
    "        rnn_out = self.leakyrelu(rnn_out)\n",
    "        rnn_out = self.dropout(rnn_out)\n",
    "        linear_out = self.linear(rnn_out)\n",
    "        return linear_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Architecture #0\n",
      "--------------------\n",
      "Epoch 0: Dev Accuracy: 0.75 Dev Precision: nan Dev Recall: 0.0 Dev Loss:0.9023586511611938\n",
      "Epoch 1: Dev Accuracy: 0.75 Dev Precision: nan Dev Recall: 0.0 Dev Loss:0.8959474563598633\n",
      "Epoch 2: Dev Accuracy: 0.75 Dev Precision: nan Dev Recall: 0.0 Dev Loss:0.89100581407547\n",
      "Epoch 3: Dev Accuracy: 0.75 Dev Precision: nan Dev Recall: 0.0 Dev Loss:0.899985671043396\n",
      "Epoch 4: Dev Accuracy: 0.5 Dev Precision: 0.0 Dev Recall: 0.0 Dev Loss:0.9065250158309937\n",
      "Epoch 5: Dev Accuracy: 0.5 Dev Precision: 0.0 Dev Recall: 0.0 Dev Loss:0.907604455947876\n",
      "Epoch 6: Dev Accuracy: 0.5 Dev Precision: 0.0 Dev Recall: 0.0 Dev Loss:0.9106559753417969\n",
      "Epoch 7: Dev Accuracy: 0.5 Dev Precision: 0.0 Dev Recall: 0.0 Dev Loss:0.905109703540802\n",
      "Epoch 8: Dev Accuracy: 0.5 Dev Precision: 0.0 Dev Recall: 0.0 Dev Loss:0.9040641188621521\n",
      "Epoch 9: Dev Accuracy: 0.5 Dev Precision: 0.0 Dev Recall: 0.0 Dev Loss:0.9007970094680786\n",
      "--------------------\n",
      "\n",
      "Architecture #1\n",
      "--------------------\n",
      "Epoch 0: Dev Accuracy: 0.25 Dev Precision: 0.25 Dev Recall: 1.0 Dev Loss:0.9248777627944946\n",
      "Epoch 1: Dev Accuracy: 0.25 Dev Precision: 0.25 Dev Recall: 1.0 Dev Loss:0.9010964632034302\n",
      "Epoch 2: Dev Accuracy: 0.75 Dev Precision: nan Dev Recall: 0.0 Dev Loss:0.8892979025840759\n",
      "Epoch 3: Dev Accuracy: 0.75 Dev Precision: nan Dev Recall: 0.0 Dev Loss:0.8837892413139343\n",
      "Epoch 4: Dev Accuracy: 0.5 Dev Precision: 0.3333333432674408 Dev Recall: 1.0 Dev Loss:0.8756585121154785\n",
      "Epoch 5: Dev Accuracy: 0.5 Dev Precision: 0.3333333432674408 Dev Recall: 1.0 Dev Loss:0.8695124387741089\n",
      "Epoch 6: Dev Accuracy: 0.5 Dev Precision: 0.3333333432674408 Dev Recall: 1.0 Dev Loss:0.8589781522750854\n",
      "Epoch 7: Dev Accuracy: 0.75 Dev Precision: nan Dev Recall: 0.0 Dev Loss:0.8572547435760498\n",
      "Epoch 8: Dev Accuracy: 0.75 Dev Precision: nan Dev Recall: 0.0 Dev Loss:0.8636214733123779\n",
      "Epoch 9: Dev Accuracy: 0.75 Dev Precision: nan Dev Recall: 0.0 Dev Loss:0.8727409243583679\n",
      "--------------------\n",
      "\n",
      "Architecture #2\n",
      "--------------------\n",
      "Epoch 0: Dev Accuracy: 0.75 Dev Precision: nan Dev Recall: 0.0 Dev Loss:0.8835586905479431\n",
      "Epoch 1: Dev Accuracy: 0.75 Dev Precision: nan Dev Recall: 0.0 Dev Loss:0.8838711977005005\n",
      "Epoch 2: Dev Accuracy: 0.75 Dev Precision: nan Dev Recall: 0.0 Dev Loss:0.8824276924133301\n",
      "Epoch 3: Dev Accuracy: 0.75 Dev Precision: nan Dev Recall: 0.0 Dev Loss:0.8820998072624207\n",
      "Epoch 4: Dev Accuracy: 0.75 Dev Precision: nan Dev Recall: 0.0 Dev Loss:0.8829041123390198\n",
      "Epoch 5: Dev Accuracy: 0.75 Dev Precision: nan Dev Recall: 0.0 Dev Loss:0.8827279806137085\n",
      "Epoch 6: Dev Accuracy: 0.75 Dev Precision: nan Dev Recall: 0.0 Dev Loss:0.8811489343643188\n",
      "Epoch 7: Dev Accuracy: 0.75 Dev Precision: nan Dev Recall: 0.0 Dev Loss:0.8808539509773254\n",
      "Epoch 8: Dev Accuracy: 0.75 Dev Precision: nan Dev Recall: 0.0 Dev Loss:0.8814478516578674\n",
      "Epoch 9: Dev Accuracy: 0.75 Dev Precision: nan Dev Recall: 0.0 Dev Loss:0.8816879391670227\n",
      "--------------------\n",
      "\n",
      "Architecture #3\n",
      "--------------------\n",
      "Epoch 0: Dev Accuracy: 0.25 Dev Precision: 0.25 Dev Recall: 1.0 Dev Loss:0.8998100757598877\n",
      "Epoch 1: Dev Accuracy: 0.5 Dev Precision: 0.3333333432674408 Dev Recall: 1.0 Dev Loss:0.8936474919319153\n",
      "Epoch 2: Dev Accuracy: 0.5 Dev Precision: 0.3333333432674408 Dev Recall: 1.0 Dev Loss:0.8844476938247681\n",
      "Epoch 3: Dev Accuracy: 0.5 Dev Precision: 0.3333333432674408 Dev Recall: 1.0 Dev Loss:0.8748250007629395\n",
      "Epoch 4: Dev Accuracy: 0.75 Dev Precision: nan Dev Recall: 0.0 Dev Loss:0.864903450012207\n",
      "Epoch 5: Dev Accuracy: 0.75 Dev Precision: nan Dev Recall: 0.0 Dev Loss:0.8588882088661194\n",
      "Epoch 6: Dev Accuracy: 0.75 Dev Precision: nan Dev Recall: 0.0 Dev Loss:0.8500980138778687\n",
      "Epoch 7: Dev Accuracy: 0.75 Dev Precision: nan Dev Recall: 0.0 Dev Loss:0.8256865739822388\n",
      "Epoch 8: Dev Accuracy: 0.5 Dev Precision: 0.3333333432674408 Dev Recall: 1.0 Dev Loss:0.8120734691619873\n",
      "Epoch 9: Dev Accuracy: 0.75 Dev Precision: nan Dev Recall: 0.0 Dev Loss:0.8007317185401917\n",
      "--------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Store training results\n",
    "df = pd.DataFrame(columns=['architecture', 'model_type', 'embeddings',\n",
    "                           'hidden', 'num_layers', 'dropouts',\n",
    "                           'bidirectional', 'learning_rate', 'epochs',\n",
    "                           'dev_acc', 'dev_prec', 'dev_recall',\n",
    "                           'metric'])\n",
    "\n",
    "# Model architecture parameters\n",
    "RNN_TYPES = ['RNN', 'LSTM']\n",
    "INPUT_DIM = len(TEXT.vocab)\n",
    "EMBEDDING_SIZES = [32, 64,]# 128, 256]\n",
    "HIDDEN_SIZES = [1/3,]# 2/3]\n",
    "OUTPUT_SIZE = 1\n",
    "NUM_LAYERS = [1,]#] 2]\n",
    "DROPOUTS = [0.5,]#] 0.75]\n",
    "BIDIRECTIONALS = [False,]# True]\n",
    "PADDING_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
    "\n",
    "# Model training hyperparameters\n",
    "LEARNING_RATE = [0.01,]#] 0.0001]\n",
    "train_len = 0\n",
    "train_pos = 0\n",
    "for batch in train_it:\n",
    "    train_len += len(batch.decision_binary)\n",
    "    train_pos += batch.decision_binary.sum().item()\n",
    "POS_WEIGHT = torch.tensor([(train_len - train_pos) / train_pos])\n",
    "if USE_CUDA:\n",
    "    POS_WEIGHT = POS_WEIGHT.cuda()\n",
    "EPOCHS = 10\n",
    "\n",
    "# Iterator over various model parameters\n",
    "param_iter = product (RNN_TYPES, EMBEDDING_SIZES, HIDDEN_SIZES,\n",
    "                      NUM_LAYERS, DROPOUTS, BIDIRECTIONALS,\n",
    "                      LEARNING_RATE)\n",
    "\n",
    "# Magic loop\n",
    "best_acc = (None, None)\n",
    "best_rec = (None, None)\n",
    "best_prec = (None, None)\n",
    "for i, (rnn_type, embed_size, hidden_size, num_layers, dropout,\\\n",
    "    bidirectional, lr) in enumerate(param_iter):\n",
    "    print(f'Architecture #{i}\\n' + '-' * 20)\n",
    "    hidden_dim = int(hidden_size * embed_size)\n",
    "    model = RNN(rnn_type, INPUT_DIM, embed_size, hidden_dim,\n",
    "                OUTPUT_SIZE, num_layers, dropout, bidirectional,\n",
    "                PADDING_IDX)\n",
    "    \n",
    "    tm = TrainingModule(model, lr, POS_WEIGHT, USE_CUDA, EPOCHS)\n",
    "    \n",
    "    best_models = tm.train_model(train_it, val_it)\n",
    "    \n",
    "    for metric, best_model in best_models.items():\n",
    "        row = [i, rnn_type, embed_size, hidden_size, num_layers, dropout,\n",
    "               bidirectional, lr, EPOCHS, best_model.accuracy,\n",
    "               best_model.precision, best_model.recall, metric]\n",
    "        df.loc[len(df)] = row\n",
    "        if best_acc[0] is None or best_model.accuracy > best_acc[1]:\n",
    "            best_acc = (copy.deepcopy(best_model.model), best_model.accuracy)\n",
    "        if best_rec[0] is None or best_model.recall > best_rec[1]:\n",
    "            best_rec = (copy.deepcopy(best_model.model), best_model.recall)\n",
    "        if best_prec[0] is None or isnan(best_prec[1]) or\\\n",
    "          best_model.precision > best_prec[1]:\n",
    "            best_prec = (copy.deepcopy(best_model.model), best_model.precision)\n",
    "    \n",
    "    print('-' * 20 + '\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save results of model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_PREFIX = 'results/RNNCustom_'\n",
    "df.to_csv(f'{SAVE_PREFIX}models.csv')\n",
    "torch.save(best_acc[0], f'{SAVE_PREFIX}best_acc.pt')\n",
    "torch.save(best_rec[0], f'{SAVE_PREFIX}best_rec.pt')\n",
    "torch.save(best_prec[0], f'{SAVE_PREFIX}best_prec.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adv-ml",
   "language": "python",
   "name": "adv-ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
